<!DOCTYPE html>
<html lang="es-ES">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.83.1" /><meta name="theme-color" content="#fff" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>Calidad del vino - Un problema de regresión | Lords of Machine Learning</title>

    <link rel="stylesheet" href="/css/meme.min.317d84c7f6754ad23a2ae219d212f73a900416875fb1144e27652ca955c5aac2.css"/>

    
    
        <script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lunr-languages@1.4.0/min/lunr.stemmer.support.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lunr-languages@1.4.0/min/lunr.es.min.js" defer></script><script src="/js/meme.min.49400d21a299355489a0a02cf7737ef1e4e5fe75fe5bd16cd756376c2bb6b749.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" /></noscript>

    <meta name="author" content="Antonio Méndez" /><meta name="description" content="En este post repasaremos las principales fases que componen un proyecto de Machine Learning.
Existen ocho pasos principales:
  Encuadrar el problema y disponer de la visión global.
  Obtener los datos.
  Explorar los datos para obtener ideas." />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="Lords of Machine Learning" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="Lords of Machine Learning" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2020-12-18T11:10:46+02:00",
        "dateModified": "2021-05-31T11:37:35+02:00",
        "url": "https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/",
        "headline": "Calidad del vino - Un problema de regresión",
        "description": "En este post repasaremos las principales fases que componen un proyecto de Machine Learning.\nExisten ocho pasos principales:\n  Encuadrar el problema y disponer de la visión global.\n  Obtener los datos.\n  Explorar los datos para obtener ideas.",
        "inLanguage" : "es-ES",
        "articleSection": "posts",
        "wordCount":  2942 ,
        "image": ["https://sgtsteiner.github.io/images/wine-glasses-1246240_1280.jpg","https://sgtsteiner.github.io/images/output_19_0.png","https://sgtsteiner.github.io/images/output_25_0.png","https://sgtsteiner.github.io/images/output_28_0.png","https://sgtsteiner.github.io/images/output_52_0.png","https://sgtsteiner.github.io/images/output_54_0.png","https://sgtsteiner.github.io/images/output_63_0.png","https://sgtsteiner.github.io/images/output_67_1.png","https://sgtsteiner.github.io/images/output_70_0.png","https://sgtsteiner.github.io/images/output_73_0.png"],
        "author": {
            "@type": "Person",
            "description": "Sgt. Steiner",
            "email": "futitotal@gmail.com",
            "image": "https://sgtsteiner.github.io/icons/apple-touch-icon.png",
            "url": "https://sgtsteiner.github.io/",
            "name": "Antonio Méndez"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es)",
        "publisher": {
            "@type": "Organization",
            "name": "Lords of Machine Learning",
            "logo": {
                "@type": "ImageObject",
                "url": "https://sgtsteiner.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://sgtsteiner.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://sgtsteiner.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />


<meta name="twitter:site" content="@Steiner_69" />
<meta name="twitter:creator" content="@Steiner_69" />

    



<meta property="og:title" content="Calidad del vino - Un problema de regresión" />
<meta property="og:description" content="En este post repasaremos las principales fases que componen un proyecto de Machine Learning.
Existen ocho pasos principales:
  Encuadrar el problema y disponer de la visión global.
  Obtener los datos.
  Explorar los datos para obtener ideas." />
<meta property="og:url" content="https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/" />
<meta property="og:site_name" content="Lords of Machine Learning" />
<meta property="og:locale" content="es" /><meta property="og:image" content="https://sgtsteiner.github.io/images/wine-glasses-1246240_1280.jpg" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2020-12-18T11:10:46&#43;02:00" />
    <meta property="article:modified_time" content="2021-05-31T11:37:35&#43;02:00" />
    
    <meta property="article:section" content="posts" />



    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">Lords of Machine Learning</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/posts/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon archive"><path d="M32 448c0 17.7 14.3 32 32 32h384c17.7 0 32-14.3 32-32V160H32v288zm160-212c0-6.6 5.4-12 12-12h104c6.6 0 12 5.4 12 12v8c0 6.6-5.4 12-12 12H204c-6.6 0-12-5.4-12-12v-8zM480 32H32C14.3 32 0 46.3 0 64v48c0 8.8 7.2 16 16 16h480c8.8 0 16-7.2 16-16V64c0-17.7-14.3-32-32-32z"/></svg><span class="menu-item-name">Posts</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255 0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255 0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255 0-24 10.745-24 24zm386.667-56H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24z"/></svg><span class="menu-item-name">Categories</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">Tags</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">About</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
            
                <li class="menu-item search-item">
                        <form id="search" class="search" role="search">
    <label for="search-input"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon search-icon"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></label>
    <input type="search" id="search-input" class="search-input">
</form>

<template id="search-result" hidden>
    <article class="content post">
        <h2 class="post-title"><a class="summary-title-link"></a></h2>
        <summary class="summary"></summary>
        <div class="read-more-container">
            <a class="read-more-link"> »</a>
        </div>
    </article>
</template>

                    </li>
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-small-caps="true" data-align="default" data-type="posts" data-toc-num="true">

            <h1 class="post-title p-name">Calidad del vino - Un problema de regresión</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2020-12-18T11:10:46&#43;02:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;18.12.2020</time>
    
    
        
        <time datetime="2021-05-31T11:37:35&#43;02:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;31.5.2021</time>
    
    
    
        
        
        
            
                <span class="post-meta-item category"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href="/categories/tutoriales/" class="category-link p-category">tutoriales</a></span>
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;2942</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;14&nbsp;</span>
    
    
    
</div>

            

            <div class="post-body e-content">
              <p style="text-indent:0"><span class="drop-cap">E</span>n este post repasaremos las principales fases que componen un proyecto de Machine Learning.</p>
<p>Existen ocho pasos principales:</p>
<ol>
<li>
<p>Encuadrar el problema y disponer de la visión global.</p>
</li>
<li>
<p>Obtener los datos.</p>
</li>
<li>
<p>Explorar los datos para obtener ideas.</p>
</li>
<li>
<p>Preparar los datos para exponer lo mejor posible los patrones de datos subyacentes a los algoritmos de Machine Learning.</p>
</li>
<li>
<p>Explorar muchos modelos diferentes y preseleccionar los mejores.</p>
</li>
<li>
<p>Afinar nuestros modelos y combinarlos en una gran solución.</p>
</li>
<li>
<p>Presentar nuestra solución.</p>
</li>
<li>
<p>Implantar, monitorizar y mantener nuestro sistema.</p>
</li>
</ol>
<p>Disponemos un conjunto de datos que contiene diversas características de variantes de tinto y blanco del vino portugués &ldquo;Vinho Verde&rdquo;. Disponemos de variables químicas, como son la cantidad de alcohol, ácido cítrico, acidez, densidad, pH, etc; así como de una variable sensorial y subjetiva como es la puntuación con la que un grupo de expertos calificaron la calidad del vino: entre 0 (muy malo) y 10 (muy excelente).</p>
<p>El objetivo es desarrollar un modelo que pueda predecir la puntuación de calidad dados dichos indicadores bioquímicos.</p>
<p>Lo primero que nos viene a la mente son una serie de preguntas básicas:</p>
<ul>
<li>
<p>¿Cómo se enmarcaría este problema (supervisado, no supervisado, etc.)?</p>
</li>
<li>
<p>¿Cuál es la variable objetivo? ¿Cuáles son los predictores?</p>
</li>
<li>
<p>¿Cómo vamos a medir el rendimiento de nuestro modelo?</p>
</li>
</ul>
<p><img src="/images/wine-glasses-1246240_1280.jpg" alt="wine glasses"></p>
<p>El codigo python utilizado en este artículo está disponible en mi <a href="https://github.com/SgtSteiner/DataScience/blob/master/Wine%20Quality/red-wine-quality-regression_v3.ipynb" target="_blank" rel="noopener">repositorio github</a></p>
<p>En primer lugar importamos todas las librerías necesarias:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">SGDRegressor</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">ElasticNet</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">ExtraTreesRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span></code></pre></div>
<h2 id="obtención-de-los-datos"><a href="#obtención-de-los-datos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Obtención de los datos</h2>
<p>El dataset se encuentra igualmente disponible en <a href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" target="_blank" rel="noopener">Kaggle</a> o en <a href="https://archive.ics.uci.edu/ml/datasets/wine+quality" target="_blank" rel="noopener">UCI</a></p>
<p>Podemos cargarlo directamente desde la url o una vez descargado desde nuestra carpeta <code>data</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;data/wine-quality/winequality-red.csv&#34;</span><span class="p">)</span></code></pre></div>
<p><strong>Verificamos el tamaño y el tipo de los datos</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(1599, 12)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fixed acidity</th>
      <th>volatile acidity</th>
      <th>citric acid</th>
      <th>residual sugar</th>
      <th>chlorides</th>
      <th>free sulfur dioxide</th>
      <th>total sulfur dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.8</td>
      <td>0.88</td>
      <td>0.00</td>
      <td>2.6</td>
      <td>0.098</td>
      <td>25.0</td>
      <td>67.0</td>
      <td>0.9968</td>
      <td>3.20</td>
      <td>0.68</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.8</td>
      <td>0.76</td>
      <td>0.04</td>
      <td>2.3</td>
      <td>0.092</td>
      <td>15.0</td>
      <td>54.0</td>
      <td>0.9970</td>
      <td>3.26</td>
      <td>0.65</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.2</td>
      <td>0.28</td>
      <td>0.56</td>
      <td>1.9</td>
      <td>0.075</td>
      <td>17.0</td>
      <td>60.0</td>
      <td>0.9980</td>
      <td>3.16</td>
      <td>0.58</td>
      <td>9.8</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
      <td>5</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span><span class="o">.</span><span class="n">info</span><span class="p">()</span></code></pre></div>
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1599 entries, 0 to 1598
Data columns (total 12 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         1599 non-null   float64
 1   volatile acidity      1599 non-null   float64
 2   citric acid           1599 non-null   float64
 3   residual sugar        1599 non-null   float64
 4   chlorides             1599 non-null   float64
 5   free sulfur dioxide   1599 non-null   float64
 6   total sulfur dioxide  1599 non-null   float64
 7   density               1599 non-null   float64
 8   pH                    1599 non-null   float64
 9   sulphates             1599 non-null   float64
 10  alcohol               1599 non-null   float64
 11  quality               1599 non-null   int64  
dtypes: float64(11), int64(1)
memory usage: 150.0 KB
</code></pre>
<p>Realizamos una serie de comprobaciones para conocer la naturaleza de los datos con los que vamos a trabajar: tipo, valores únicos, número de valores únicos y su porcentaje, valores medios y desviación estándar.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;Type&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">dtypes</span><span class="p">,</span>
              <span class="s2">&#34;Unique&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">nunique</span><span class="p">(),</span>
              <span class="s2">&#34;Null&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
              <span class="s2">&#34;Null percent&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">red</span><span class="p">),</span>
              <span class="s2">&#34;Mean&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
              <span class="s2">&#34;Std&#34;</span><span class="p">:</span> <span class="n">red</span><span class="o">.</span><span class="n">std</span><span class="p">()})</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Type</th>
      <th>Unique</th>
      <th>Null</th>
      <th>Null percent</th>
      <th>Mean</th>
      <th>Std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fixed acidity</th>
      <td>float64</td>
      <td>96</td>
      <td>0</td>
      <td>0.0</td>
      <td>8.319637</td>
      <td>1.741096</td>
    </tr>
    <tr>
      <th>volatile acidity</th>
      <td>float64</td>
      <td>143</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.527821</td>
      <td>0.179060</td>
    </tr>
    <tr>
      <th>citric acid</th>
      <td>float64</td>
      <td>80</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.270976</td>
      <td>0.194801</td>
    </tr>
    <tr>
      <th>residual sugar</th>
      <td>float64</td>
      <td>91</td>
      <td>0</td>
      <td>0.0</td>
      <td>2.538806</td>
      <td>1.409928</td>
    </tr>
    <tr>
      <th>chlorides</th>
      <td>float64</td>
      <td>153</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.087467</td>
      <td>0.047065</td>
    </tr>
    <tr>
      <th>free sulfur dioxide</th>
      <td>float64</td>
      <td>60</td>
      <td>0</td>
      <td>0.0</td>
      <td>15.874922</td>
      <td>10.460157</td>
    </tr>
    <tr>
      <th>total sulfur dioxide</th>
      <td>float64</td>
      <td>144</td>
      <td>0</td>
      <td>0.0</td>
      <td>46.467792</td>
      <td>32.895324</td>
    </tr>
    <tr>
      <th>density</th>
      <td>float64</td>
      <td>436</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.996747</td>
      <td>0.001887</td>
    </tr>
    <tr>
      <th>pH</th>
      <td>float64</td>
      <td>89</td>
      <td>0</td>
      <td>0.0</td>
      <td>3.311113</td>
      <td>0.154386</td>
    </tr>
    <tr>
      <th>sulphates</th>
      <td>float64</td>
      <td>96</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.658149</td>
      <td>0.169507</td>
    </tr>
    <tr>
      <th>alcohol</th>
      <td>float64</td>
      <td>65</td>
      <td>0</td>
      <td>0.0</td>
      <td>10.422983</td>
      <td>1.065668</td>
    </tr>
    <tr>
      <th>quality</th>
      <td>int64</td>
      <td>6</td>
      <td>0</td>
      <td>0.0</td>
      <td>5.636023</td>
      <td>0.807569</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>Mmmmm, no existen valores nulos, ¡qué buen dataset!</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fixed acidity</th>
      <td>1599.0</td>
      <td>8.319637</td>
      <td>1.741096</td>
      <td>4.60000</td>
      <td>7.1000</td>
      <td>7.90000</td>
      <td>9.200000</td>
      <td>15.90000</td>
    </tr>
    <tr>
      <th>volatile acidity</th>
      <td>1599.0</td>
      <td>0.527821</td>
      <td>0.179060</td>
      <td>0.12000</td>
      <td>0.3900</td>
      <td>0.52000</td>
      <td>0.640000</td>
      <td>1.58000</td>
    </tr>
    <tr>
      <th>citric acid</th>
      <td>1599.0</td>
      <td>0.270976</td>
      <td>0.194801</td>
      <td>0.00000</td>
      <td>0.0900</td>
      <td>0.26000</td>
      <td>0.420000</td>
      <td>1.00000</td>
    </tr>
    <tr>
      <th>residual sugar</th>
      <td>1599.0</td>
      <td>2.538806</td>
      <td>1.409928</td>
      <td>0.90000</td>
      <td>1.9000</td>
      <td>2.20000</td>
      <td>2.600000</td>
      <td>15.50000</td>
    </tr>
    <tr>
      <th>chlorides</th>
      <td>1599.0</td>
      <td>0.087467</td>
      <td>0.047065</td>
      <td>0.01200</td>
      <td>0.0700</td>
      <td>0.07900</td>
      <td>0.090000</td>
      <td>0.61100</td>
    </tr>
    <tr>
      <th>free sulfur dioxide</th>
      <td>1599.0</td>
      <td>15.874922</td>
      <td>10.460157</td>
      <td>1.00000</td>
      <td>7.0000</td>
      <td>14.00000</td>
      <td>21.000000</td>
      <td>72.00000</td>
    </tr>
    <tr>
      <th>total sulfur dioxide</th>
      <td>1599.0</td>
      <td>46.467792</td>
      <td>32.895324</td>
      <td>6.00000</td>
      <td>22.0000</td>
      <td>38.00000</td>
      <td>62.000000</td>
      <td>289.00000</td>
    </tr>
    <tr>
      <th>density</th>
      <td>1599.0</td>
      <td>0.996747</td>
      <td>0.001887</td>
      <td>0.99007</td>
      <td>0.9956</td>
      <td>0.99675</td>
      <td>0.997835</td>
      <td>1.00369</td>
    </tr>
    <tr>
      <th>pH</th>
      <td>1599.0</td>
      <td>3.311113</td>
      <td>0.154386</td>
      <td>2.74000</td>
      <td>3.2100</td>
      <td>3.31000</td>
      <td>3.400000</td>
      <td>4.01000</td>
    </tr>
    <tr>
      <th>sulphates</th>
      <td>1599.0</td>
      <td>0.658149</td>
      <td>0.169507</td>
      <td>0.33000</td>
      <td>0.5500</td>
      <td>0.62000</td>
      <td>0.730000</td>
      <td>2.00000</td>
    </tr>
    <tr>
      <th>alcohol</th>
      <td>1599.0</td>
      <td>10.422983</td>
      <td>1.065668</td>
      <td>8.40000</td>
      <td>9.5000</td>
      <td>10.20000</td>
      <td>11.100000</td>
      <td>14.90000</td>
    </tr>
    <tr>
      <th>quality</th>
      <td>1599.0</td>
      <td>5.636023</td>
      <td>0.807569</td>
      <td>3.00000</td>
      <td>5.0000</td>
      <td>6.00000</td>
      <td>6.000000</td>
      <td>8.00000</td>
    </tr>
  </tbody>
</table></div>
</div>
<h2 id="exploración-de-los-datos"><a href="#exploración-de-los-datos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Exploración de los datos</h2>
<p>El siguiente paso será realizar un análisis exploratorio de los datos. ¿Cómo se distribuyen las características?</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">red</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">12</span><span class="p">));</span></code></pre></div>
<p><img src="/images/output_19_0.png" alt="png"></p>
<p>Verifiquemos ahora cómo se distribuye nuestra variable objetivo (la puntuación de calidad):</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Percentage of quality scores&#34;</span><span class="p">)</span>
<span class="n">red</span><span class="p">[</span><span class="s2">&#34;quality&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span></code></pre></div>
<pre><code>Percentage of quality scores

5    42.589118
6    39.899937
7    12.445278
4     3.314572
8     1.125704
3     0.625391
Name: quality, dtype: float64
</code></pre>
<p>Podemos comprobar que se encuentra significativamente desbalanceada. La mayoría de las instancias (82%) tienen puntuaciones de 5 ó 6.</p>
<p>Vamos a verificar las correlaciones entre las características del dataset:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">red</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">corr_matrix</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fixed acidity</th>
      <th>volatile acidity</th>
      <th>citric acid</th>
      <th>residual sugar</th>
      <th>chlorides</th>
      <th>free sulfur dioxide</th>
      <th>total sulfur dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fixed acidity</th>
      <td>1.000000</td>
      <td>-0.256131</td>
      <td>0.671703</td>
      <td>0.114777</td>
      <td>0.093705</td>
      <td>-0.153794</td>
      <td>-0.113181</td>
      <td>0.668047</td>
      <td>-0.682978</td>
      <td>0.183006</td>
      <td>-0.061668</td>
      <td>0.124052</td>
    </tr>
    <tr>
      <th>volatile acidity</th>
      <td>-0.256131</td>
      <td>1.000000</td>
      <td>-0.552496</td>
      <td>0.001918</td>
      <td>0.061298</td>
      <td>-0.010504</td>
      <td>0.076470</td>
      <td>0.022026</td>
      <td>0.234937</td>
      <td>-0.260987</td>
      <td>-0.202288</td>
      <td>-0.390558</td>
    </tr>
    <tr>
      <th>citric acid</th>
      <td>0.671703</td>
      <td>-0.552496</td>
      <td>1.000000</td>
      <td>0.143577</td>
      <td>0.203823</td>
      <td>-0.060978</td>
      <td>0.035533</td>
      <td>0.364947</td>
      <td>-0.541904</td>
      <td>0.312770</td>
      <td>0.109903</td>
      <td>0.226373</td>
    </tr>
    <tr>
      <th>residual sugar</th>
      <td>0.114777</td>
      <td>0.001918</td>
      <td>0.143577</td>
      <td>1.000000</td>
      <td>0.055610</td>
      <td>0.187049</td>
      <td>0.203028</td>
      <td>0.355283</td>
      <td>-0.085652</td>
      <td>0.005527</td>
      <td>0.042075</td>
      <td>0.013732</td>
    </tr>
    <tr>
      <th>chlorides</th>
      <td>0.093705</td>
      <td>0.061298</td>
      <td>0.203823</td>
      <td>0.055610</td>
      <td>1.000000</td>
      <td>0.005562</td>
      <td>0.047400</td>
      <td>0.200632</td>
      <td>-0.265026</td>
      <td>0.371260</td>
      <td>-0.221141</td>
      <td>-0.128907</td>
    </tr>
    <tr>
      <th>free sulfur dioxide</th>
      <td>-0.153794</td>
      <td>-0.010504</td>
      <td>-0.060978</td>
      <td>0.187049</td>
      <td>0.005562</td>
      <td>1.000000</td>
      <td>0.667666</td>
      <td>-0.021946</td>
      <td>0.070377</td>
      <td>0.051658</td>
      <td>-0.069408</td>
      <td>-0.050656</td>
    </tr>
    <tr>
      <th>total sulfur dioxide</th>
      <td>-0.113181</td>
      <td>0.076470</td>
      <td>0.035533</td>
      <td>0.203028</td>
      <td>0.047400</td>
      <td>0.667666</td>
      <td>1.000000</td>
      <td>0.071269</td>
      <td>-0.066495</td>
      <td>0.042947</td>
      <td>-0.205654</td>
      <td>-0.185100</td>
    </tr>
    <tr>
      <th>density</th>
      <td>0.668047</td>
      <td>0.022026</td>
      <td>0.364947</td>
      <td>0.355283</td>
      <td>0.200632</td>
      <td>-0.021946</td>
      <td>0.071269</td>
      <td>1.000000</td>
      <td>-0.341699</td>
      <td>0.148506</td>
      <td>-0.496180</td>
      <td>-0.174919</td>
    </tr>
    <tr>
      <th>pH</th>
      <td>-0.682978</td>
      <td>0.234937</td>
      <td>-0.541904</td>
      <td>-0.085652</td>
      <td>-0.265026</td>
      <td>0.070377</td>
      <td>-0.066495</td>
      <td>-0.341699</td>
      <td>1.000000</td>
      <td>-0.196648</td>
      <td>0.205633</td>
      <td>-0.057731</td>
    </tr>
    <tr>
      <th>sulphates</th>
      <td>0.183006</td>
      <td>-0.260987</td>
      <td>0.312770</td>
      <td>0.005527</td>
      <td>0.371260</td>
      <td>0.051658</td>
      <td>0.042947</td>
      <td>0.148506</td>
      <td>-0.196648</td>
      <td>1.000000</td>
      <td>0.093595</td>
      <td>0.251397</td>
    </tr>
    <tr>
      <th>alcohol</th>
      <td>-0.061668</td>
      <td>-0.202288</td>
      <td>0.109903</td>
      <td>0.042075</td>
      <td>-0.221141</td>
      <td>-0.069408</td>
      <td>-0.205654</td>
      <td>-0.496180</td>
      <td>0.205633</td>
      <td>0.093595</td>
      <td>1.000000</td>
      <td>0.476166</td>
    </tr>
    <tr>
      <th>quality</th>
      <td>0.124052</td>
      <td>-0.390558</td>
      <td>0.226373</td>
      <td>0.013732</td>
      <td>-0.128907</td>
      <td>-0.050656</td>
      <td>-0.185100</td>
      <td>-0.174919</td>
      <td>-0.057731</td>
      <td>0.251397</td>
      <td>0.476166</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">red</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></div>
<p><img src="/images/output_25_0.png" alt="png"></p>
<p>Existen correlaciones positivas entre las características:</p>
<ul>
<li><code>fixed acidity</code> con <code>citric acid</code> y <code>densidad</code>,</li>
<li><code>free sulfur dioxide</code> con <code>total sulfur dioxide</code>,</li>
<li><code>alcohol</code> con <code>quality</code></li>
</ul>
<p>y correlaciones negativas entre las caracteríticas:</p>
<ul>
<li><code>fixed acidity</code> con <code>pH</code>,</li>
<li><code>volatile acidity</code> con <code>citric acid</code>,</li>
<li><code>citric acid</code> con <code>pH</code>,</li>
<li><code>density</code> con <code>alcohol</code></li>
</ul>
<p>Mostremos sólo las correlaciones de la variable objetivo con el resto de características:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">corr_matrix</span><span class="p">[</span><span class="s2">&#34;quality&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;quality&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>alcohol                 0.476166
sulphates               0.251397
citric acid             0.226373
fixed acidity           0.124052
residual sugar          0.013732
free sulfur dioxide    -0.050656
pH                     -0.057731
chlorides              -0.128907
density                -0.174919
total sulfur dioxide   -0.185100
volatile acidity       -0.390558
Name: quality, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">corr_matrix</span><span class="p">[</span><span class="s2">&#34;quality&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;quality&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Attribute correlations with quality&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></div>
<p><img src="/images/output_28_0.png" alt="png"></p>
<p>Podemos observar una correlación positiva con el atributo <code>alcohol</code> y negativa con <code>volatile acidity</code>.</p>
<h2 id="preparación-de-los-datos"><a href="#preparación-de-los-datos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Preparación de los datos</h2>
<p>En primer lugar vamos a crear el conjunto de predictores y el conjunto con la variable objetivo:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">predict_columns</span> <span class="o">=</span> <span class="n">red</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">predict_columns</span></code></pre></div>
<pre><code>Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol'],
      dtype='object')
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">red</span><span class="p">[</span><span class="n">predict_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">red</span><span class="p">[</span><span class="s2">&#34;quality&#34;</span><span class="p">]</span></code></pre></div>
<p>Posteriormente, creamos los conjuntos de entrenamiento y prueba, siendo el conjunto de entrenamiento un 80% del dataset completo y el 20% restante el conjunto de prueba:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>((1279, 11), (1279,))
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>((320, 11), (320,))
</code></pre>
<h2 id="línea-base"><a href="#línea-base" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Línea base</h2>
<p>Para determinar adecuadamente si nuestro modelo es mejor o peor, primero tenemos que definir una línea base con la que poder comparar. Para ello vamos a entrenar algunos regresores <em>dummy</em> cuyos resultados usaremos como línea base de comparación.</p>
<p>Este regresor dummy predice de manera constante la puntuación 5, la más frecuente:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rg_dummy</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&#34;constant&#34;</span><span class="p">,</span> <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">rg_dummy</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>DummyRegressor(constant=array(5), strategy='constant')
</code></pre>
<p>Nos creamos una función que nos permitirá evaluar nuestro modelo a lo largo de este análisis:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;Print and return cross validation of model
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;neg_mean_absolute_error&#34;</span><span class="p">,</span> <span class="s2">&#34;neg_mean_squared_error&#34;</span><span class="p">,</span> <span class="s2">&#34;r2&#34;</span><span class="p">]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    
    <span class="n">val_mae_mean</span><span class="p">,</span> <span class="n">val_mae_std</span> <span class="o">=</span> <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_absolute_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_absolute_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">train_mae_mean</span><span class="p">,</span> <span class="n">train_mae_std</span> <span class="o">=</span> <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_absolute_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                    <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_absolute_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">val_mse_mean</span><span class="p">,</span> <span class="n">val_mse_std</span> <span class="o">=</span> <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">train_mse_mean</span><span class="p">,</span> <span class="n">train_mse_std</span> <span class="o">=</span> <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_squared_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                    <span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_squared_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">val_rmse_mean</span><span class="p">,</span> <span class="n">val_rmse_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                  <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">train_rmse_mean</span><span class="p">,</span> <span class="n">train_rmse_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_squared_error&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> \
                                      <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_neg_mean_squared_error&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">val_r2_mean</span><span class="p">,</span> <span class="n">val_r2_std</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_r2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_r2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    
    <span class="n">train_r2_mean</span><span class="p">,</span> <span class="n">train_r2_std</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_r2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_r2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

    
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;Val MAE&#34;</span><span class="p">:</span> <span class="n">val_mae_mean</span><span class="p">,</span>
        <span class="s2">&#34;Val MAE std&#34;</span><span class="p">:</span> <span class="n">val_mae_std</span><span class="p">,</span>
        <span class="s2">&#34;Train MAE&#34;</span><span class="p">:</span> <span class="n">train_mae_mean</span><span class="p">,</span>
        <span class="s2">&#34;Train MAE std&#34;</span><span class="p">:</span> <span class="n">train_mae_std</span><span class="p">,</span>
        <span class="s2">&#34;Val MSE&#34;</span><span class="p">:</span> <span class="n">val_mse_mean</span><span class="p">,</span>
        <span class="s2">&#34;Val MSE std&#34;</span><span class="p">:</span> <span class="n">val_mse_std</span><span class="p">,</span>
        <span class="s2">&#34;Train MSE&#34;</span><span class="p">:</span> <span class="n">train_mse_mean</span><span class="p">,</span>
        <span class="s2">&#34;Train MSE std&#34;</span><span class="p">:</span> <span class="n">train_mse_std</span><span class="p">,</span>
        <span class="s2">&#34;Val RMSE&#34;</span><span class="p">:</span> <span class="n">val_rmse_mean</span><span class="p">,</span>
        <span class="s2">&#34;Val RMSE std&#34;</span><span class="p">:</span> <span class="n">val_rmse_std</span><span class="p">,</span>
        <span class="s2">&#34;Train RMSE&#34;</span><span class="p">:</span> <span class="n">train_rmse_mean</span><span class="p">,</span>
        <span class="s2">&#34;Train RMSE std&#34;</span><span class="p">:</span> <span class="n">train_rmse_std</span><span class="p">,</span>
        <span class="s2">&#34;Val R2&#34;</span><span class="p">:</span> <span class="n">val_r2_mean</span><span class="p">,</span>
        <span class="s2">&#34;Val R2 std&#34;</span><span class="p">:</span> <span class="n">val_r2_std</span><span class="p">,</span>
        <span class="s2">&#34;Train R2&#34;</span><span class="p">:</span> <span class="n">train_rmse_mean</span><span class="p">,</span>
        <span class="s2">&#34;Train R2 std&#34;</span><span class="p">:</span> <span class="n">train_r2_std</span><span class="p">,</span>
    <span class="p">}</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;val_MAE_mean: {val_mae_mean} - (std: {val_mae_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;train_MAE_mean: {train_mae_mean} - (std: {train_mae_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;val_MSE_mean: {val_mse_mean} - (std: {val_mse_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;train_MSE_mean: {train_mse_mean} - (std: {train_mse_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;val_RMSE_mean: {val_rmse_mean} - (std: {val_rmse_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;train_RMSE_mean: {train_rmse_mean} - (std: {train_rmse_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;val_R2_mean: {val_r2_mean} - (std: {val_r2_std})&#34;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;train_R2_mean: {train_r2_mean} - (std: {train_r2_std})&#34;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rg_scores</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">rg_dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>val_MAE_mean: 0.719365157480315 - (std: -0.06352462970037416)
train_MAE_mean: 0.7193126146346173 - (std: -0.007057414168822716)
val_MSE_mean: 1.0398868110236221 - (std: -0.12176257291946108)
train_MSE_mean: 1.0398750482672072 - (std: -0.01354074583910719)
val_RMSE_mean: 1.0180017820772593 - (std: 0.05965888627141756)
train_RMSE_mean: 1.0197209977802941 - (std: 0.006643414270421584)
val_R2_mean: -0.6192850555554466 - (std: 0.14799333040101653)
train_R2_mean: -0.5986022943608599 - (std: 0.01598456942915052)
</code></pre>
<p>Un regresor que siempre predice la puntuación de calidad más frecuente (en nuestro caso, la puntuación 5) obtiene un <strong>RMSE = 1.01</strong>.</p>
<p>Probemos ahora con un regresor dummy que predice la media de las puntuaciones de calidad:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rg_dummy</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&#34;mean&#34;</span><span class="p">)</span> <span class="c1"># Mean prediction</span>
<span class="n">rg_dummy</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>DummyRegressor()
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rg_scores</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">rg_dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>val_MAE_mean: 0.6842639509806605 - (std: -0.039939453843720794)
train_MAE_mean: 0.6836374055181736 - (std: -0.004461928774514038)
val_MSE_mean: 0.6515564887161005 - (std: -0.08938937463665708)
train_MSE_mean: 0.6505431870574859 - (std: -0.009928873673332832)
val_RMSE_mean: 0.8052590895459458 - (std: 0.05580580095057208)
train_RMSE_mean: 0.8065390950374436 - (std: 0.006154285796714715)
val_R2_mean: -0.007632943779434287 - (std: 0.010684535533448955)
train_R2_mean: 0.0 - (std: 0.0)
</code></pre>
<p>Un regresor que predice siempre la puntuación media de calidad obtiene un <strong>RMSE = 0.80</strong>. Vamos a tomar la predicción de este regresor dummy como nuestra línea base.</p>
<h2 id="entrenamiento-de-diversos-modelos"><a href="#entrenamiento-de-diversos-modelos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Entrenamiento de diversos modelos</h2>
<p>OK, ya estamos listos para entrenar varios modelos de forma rápida de diferente tipología y usando los parámetros estándar. Seleccionamos algunos modelos de regresión: <code>Linear Regression</code>, <code>Lasso</code>, <code>ElasticNet</code>, <code>Ridge</code>, <code>Extre Trees</code>, y <code>RandomForest</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">LinearRegression</span><span class="p">(),</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">ElasticNet</span><span class="p">(),</span>
          <span class="n">Ridge</span><span class="p">(),</span> <span class="n">ExtraTreesRegressor</span><span class="p">(),</span> <span class="n">RandomForestRegressor</span><span class="p">()]</span>

<span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;Lineal Regression&#34;</span><span class="p">,</span> <span class="s2">&#34;Lasso&#34;</span><span class="p">,</span> <span class="s2">&#34;ElasticNet&#34;</span><span class="p">,</span>
               <span class="s2">&#34;Ridge&#34;</span><span class="p">,</span> <span class="s2">&#34;Extra Tree&#34;</span><span class="p">,</span> <span class="s2">&#34;Random Forest&#34;</span><span class="p">]</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">mae</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">r2</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Paso {model+1} de {len(models)}&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;...running {model_names[model]}&#34;</span><span class="p">)</span>
    
    <span class="n">rg_scores</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">model</span><span class="p">],</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="n">mae</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rg_scores</span><span class="p">[</span><span class="s2">&#34;Val MAE&#34;</span><span class="p">])</span>
    <span class="n">mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rg_scores</span><span class="p">[</span><span class="s2">&#34;Val MSE&#34;</span><span class="p">])</span>
    <span class="n">rmse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rg_scores</span><span class="p">[</span><span class="s2">&#34;Val RMSE&#34;</span><span class="p">])</span>
    <span class="n">r2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rg_scores</span><span class="p">[</span><span class="s2">&#34;Val R2&#34;</span><span class="p">])</span></code></pre></div>
<pre><code>Paso 1 de 6
...running Lineal Regression
val_MAE_mean: 0.5054157041773433 - (std: -0.046264972549372924)
train_MAE_mean: 0.49951141240221786 - (std: -0.005396834677886112)
val_MSE_mean: 0.4363366846653876 - (std: -0.0713599197838867)
train_MSE_mean: 0.423559916011364 - (std: -0.007783364048942027)
val_RMSE_mean: 0.6578988186927084 - (std: 0.059210041615646476)
train_RMSE_mean: 0.6507877560250832 - (std: 0.005934022177307515)
val_R2_mean: 0.32302131635332426 - (std: 0.0972958323285871)
train_R2_mean: 0.34888336017832816 - (std: 0.008988207786517072)
Paso 2 de 6
...running Lasso
val_MAE_mean: 0.5542159398138832 - (std: -0.044044881537899525)
train_MAE_mean: 0.551926769360105 - (std: -0.005222359881914205)
val_MSE_mean: 0.5011613158962728 - (std: -0.07980261731926688)
train_MSE_mean: 0.49648903729654775 - (std: -0.00886434349442919)
val_RMSE_mean: 0.7054560563903938 - (std: 0.05910218607112876)
train_RMSE_mean: 0.7045920060170998 - (std: 0.006256385006291075)
val_R2_mean: 0.22550457016915199 - (std: 0.06858817248045986)
train_R2_mean: 0.23679715721911138 - (std: 0.008061051196907644)
Paso 3 de 6
...running ElasticNet
val_MAE_mean: 0.6484828644185054 - (std: -0.03858618665902155)
train_MAE_mean: 0.6472074434172257 - (std: -0.004861676284701619)
val_MSE_mean: 0.6260699925252777 - (std: -0.08837053843631361)
train_MSE_mean: 0.6236958050351286 - (std: -0.009753039023728842)
val_RMSE_mean: 0.7891968495348196 - (std: 0.056906284447264595)
train_RMSE_mean: 0.7897200517246066 - (std: 0.0061680579774354895)
val_R2_mean: 0.032300440343033296 - (std: 0.027013749786509673)
train_R2_mean: 0.041268269123349036 - (std: 0.0034334107542665303)
Paso 4 de 6
...running Ridge
val_MAE_mean: 0.5052017417711606 - (std: -0.04639189777979148)
train_MAE_mean: 0.5000120146851917 - (std: -0.00538293390792397)
val_MSE_mean: 0.4353611411950837 - (std: -0.07150445371257734)
train_MSE_mean: 0.4243933932521361 - (std: -0.007774091981744382)
val_RMSE_mean: 0.6571341500690723 - (std: 0.05946301378236467)
train_RMSE_mean: 0.6514279204128516 - (std: 0.0059209592739344254)
val_R2_mean: 0.32476443307512515 - (std: 0.09605257129964452)
train_R2_mean: 0.3476024511130947 - (std: 0.0089301257345918)
Paso 5 de 6
...running Extra Tree
val_MAE_mean: 0.3767233021653543 - (std: -0.048411131876621855)
train_MAE_mean: -0.0 - (std: -0.0)
val_MSE_mean: 0.33849758981299216 - (std: -0.07037684927470149)
train_MSE_mean: -0.0 - (std: -0.0)
val_RMSE_mean: 0.5784725891678845 - (std: 0.062185636560190514)
train_RMSE_mean: 0.0 - (std: 0.0)
val_R2_mean: 0.4753582472917177 - (std: 0.09435328966382882)
train_R2_mean: 1.0 - (std: 0.0)
Paso 6 de 6
...running Random Forest
val_MAE_mean: 0.421939406988189 - (std: -0.03848180259232641)
train_MAE_mean: 0.15720688154624 - (std: -0.0024955091475250693)
val_MSE_mean: 0.3536394728100393 - (std: -0.06315688035394738)
train_MSE_mean: 0.049982221460505356 - (std: -0.0012897300801719821)
val_RMSE_mean: 0.5921558699969636 - (std: 0.05468910712544724)
train_RMSE_mean: 0.22354850027354933 - (std: 0.0028791467403151403)
val_R2_mean: 0.450229047801475 - (std: 0.08970981370698214)
train_R2_mean: 0.9231573754360927 - (std: 0.0020715859571618753)
</code></pre>
<p>Veamos cuál es el rendimiento de cada uno de ellos:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;Model&#34;</span><span class="p">:</span> <span class="n">model_names</span><span class="p">,</span>
                          <span class="s2">&#34;MAE&#34;</span><span class="p">:</span> <span class="n">mae</span><span class="p">,</span>
                          <span class="s2">&#34;MSE&#34;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span>
                          <span class="s2">&#34;RMSE&#34;</span><span class="p">:</span> <span class="n">rmse</span><span class="p">,</span>
                          <span class="s2">&#34;R2&#34;</span><span class="p">:</span> <span class="n">r2</span><span class="p">})</span>
<span class="n">df_result</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>MAE</th>
      <th>MSE</th>
      <th>RMSE</th>
      <th>R2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lineal Regression</td>
      <td>0.505416</td>
      <td>0.436337</td>
      <td>0.657899</td>
      <td>0.323021</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lasso</td>
      <td>0.554216</td>
      <td>0.501161</td>
      <td>0.705456</td>
      <td>0.225505</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ElasticNet</td>
      <td>0.648483</td>
      <td>0.626070</td>
      <td>0.789197</td>
      <td>0.032300</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Ridge</td>
      <td>0.505202</td>
      <td>0.435361</td>
      <td>0.657134</td>
      <td>0.324764</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Extra Tree</td>
      <td>0.375012</td>
      <td>0.335985</td>
      <td>0.576599</td>
      <td>0.479648</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Random Forest</td>
      <td>0.422140</td>
      <td>0.356897</td>
      <td>0.594764</td>
      <td>0.445618</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_result</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&#34;RMSE&#34;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="s2">&#34;Model&#34;</span><span class="p">,</span> <span class="s2">&#34;RMSE&#34;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_52_0.png" alt="png"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_result</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&#34;R2&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="s2">&#34;Model&#34;</span><span class="p">,</span> <span class="s2">&#34;R2&#34;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_54_0.png" alt="png"></p>
<p>Analizando los resultados vemos que <strong>extra trees</strong> es el modelo que mejores resultados obtiene. RMSE = 0.576599 and R2 = 0.479648. OK, este será nuestro modelo candidato. Vamos a realizar el ajuste fino.</p>
<h2 id="fine-tune"><a href="#fine-tune" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Fine-Tune</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">&#34;auto&#34;</span><span class="p">],</span> <span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]}</span>
<span class="p">]</span>


<span class="n">xtree_reg</span> <span class="o">=</span> <span class="n">ExtraTreesRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xtree_reg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                           <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> 
                           <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>GridSearchCV(cv=5, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42),
             param_grid=[{'bootstrap': [True, False],
                          'max_features': [2, 3, 4, 5, 8, 'auto'],
                          'n_estimators': range(10, 300, 10)}],
             return_train_score=True, scoring='neg_mean_squared_error')
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span></code></pre></div>
<pre><code>{'bootstrap': False, 'max_features': 5, 'n_estimators': 160}
</code></pre>
<p>¡Es el momento de la verdad! Veamos su rendimiento en el conjunto de prueba:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">final_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;MAE: {metrics.mean_absolute_error(y_test, y_pred)}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;MSE: {metrics.mean_squared_error(y_test, y_pred)}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;R2: {final_model.score(X_test, y_test)}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>MAE: 0.38298828124999995
MSE: 0.28038391113281247
RMSE: 0.5295128998738486
R2: 0.5709542506612473
</code></pre>
<p>Bueno, ¡un poco mejor! Obtenemos un error de +/- 0.5295.</p>
<p>Podemos visualizar cómo han sido sus predicciones:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Real&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Predicted&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></div>
<p><img src="/images/output_63_0.png" alt="png"></p>
<p>Se observa una mayor concentración de predicciones en las puntuaciones centrales (5 y 6), debido a un mayor número de instancias en el dataset respecto a las demás. También podemos comprobar que las predicciones sobre las puntuaciones extremas son pésimas. Las puntuaciones 5 y 6 son las que mejores resultados ofrecen.</p>
<p>¿Cuáles son las características más relevantes?:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">feature_importances</span> <span class="o">=</span> <span class="n">final_model</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importances</span></code></pre></div>
<pre><code>array([0.06242878, 0.12054219, 0.07478461, 0.06697772, 0.06670251,
       0.05944129, 0.07925392, 0.07148382, 0.06178626, 0.12593217,
       0.21066673])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></div>
<pre><code>[(0.2106667292131454, 'alcohol'),
 (0.12593217102849735, 'sulphates'),
 (0.1205421943281732, 'volatile acidity'),
 (0.07925392046422035, 'total sulfur dioxide'),
 (0.07478461494308856, 'citric acid'),
 (0.07148382305429932, 'density'),
 (0.06697771630809285, 'residual sugar'),
 (0.06670250522733821, 'chlorides'),
 (0.062428775664599805, 'fixed acidity'),
 (0.061786258397281676, 'pH'),
 (0.05944129137126337, 'free sulfur dioxide')]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">feature_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">feature_imp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Feature Importances&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="/images/output_67_1.png" alt="png"></p>
<p>La gráfica nos muestra que las características más importantes son: <code>alcohol</code>, <code>sulphates</code> y <code>volatile acidity</code>, algo que también nos anticipaba el análisis de correlaciones que vimos anteriormente.</p>
<p>Veamos ahora cómo se distribuyen los errores:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_resul</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;Pred&#34;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">,</span>
              <span class="s2">&#34;Real&#34;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>
              <span class="s2">&#34;error&#34;</span><span class="p">:</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">,</span>
              <span class="s2">&#34;error_abs&#34;</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)})</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_resul</span><span class="p">[</span><span class="s2">&#34;error&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Error distribution&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Error&#34;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_70_0.png" alt="png"></p>
<p>Parece que los errores siguen una distribución gaussiana.</p>
<p>¿Cuál es el MAE que se produce en la puntuación de calidad 6?</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_resul</span><span class="p">[</span><span class="n">df_resul</span><span class="p">[</span><span class="s2">&#34;Real&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="mi">6</span><span class="p">])][</span><span class="s2">&#34;error&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></code></pre></div>
<pre><code>0.3437013037105609
</code></pre>
<p>Más en general ¿Cuál es el MAE que se produce en cada puntuación de calidad?</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_resul</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&#34;Real&#34;</span><span class="p">)[</span><span class="s2">&#34;error_abs&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></code></pre></div>
<pre><code>Real
3    2.268966
4    1.286657
5    0.462774
6    0.343701
7    0.617315
8    1.597190
9    3.434483
Name: error_abs, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df_resul</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&#34;Real&#34;</span><span class="p">)[</span><span class="s2">&#34;error_abs&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;MAE distribution&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;MAE&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Quality&#34;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_73_0.png" alt="png"></p>
<p>Se comprueba que en las puntuaciones de calidad extremas el error es elevado, sobre todo en la puntuación 8 y 3. Las puntuaciones 5 y 6 es donde menos error se produce.</p>
<h2 id="guardado-del-modelo"><a href="#guardado-del-modelo" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Guardado del modelo</h2>
<p>Como paso final, guardamos nuestro modelo entrenado para futuras predicciones.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">final_model</span><span class="p">,</span> <span class="s2">&#34;final_model.joblib&#34;</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></div>
<pre><code>['final_model.joblib']
</code></pre>
<h2 id="conclusiones"><a href="#conclusiones" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Conclusiones</h2>
<p>Después de probar diversos modelos, el que mejores resultados arroja es <strong>ExtraTrees</strong>. Tras un ajuste fino del mismo conseguimos una importante mejora:</p>
<ul>
<li>Nuestra línea base teníamos un MAE: 0.684263 y RMSE: 0.805259.</li>
<li>El modelo de Extra Tree obtiene un MAE: 0.382988, RMSE: 0.529512 y R2:0.570954.</li>
</ul>
<p>Sin embargo, la puntuación de R2 sigue siendo muy baja. Según dicho valor, nuestro modelo apenas puede explicar un 57% de la varianza. Es decir, el porcentaje de relación entre las variables que puede explicarse mediante nuestro modelo lineal es del 57,09%.</p>
<blockquote>
<p>Como sabemos, R2 varía entre 0 y 1. Es la proporción de la varianza en la variable dependiente (nuestra variable objetivo) que es predecible a partir de las variables independientes (nuestros predictores). Si la predicción fuera exactamente igual a lo real, R2 = 1 (es decir, 100%).</p>
</blockquote>
<p>El RMSE = 0,529. Es decir, tenemos un error típico de predicción de 0,529.</p>
<p>Según la gráfica de distribución de MAE podemos observar que nuestro modelo no es nada bueno para valores extremos de puntuación. De hecho no es capaz de predecir ninguna puntuación de 3 y apenas alguna de 8. Según vimos en la distribución de la variable objetivo, ésta se encuentra muy desbalanceada, apenas existen observaciones para los valores extremos, por lo que el modelo no tiene suficientes datos de entrenamiento para todas las puntuaciones de calidad.</p>
<p>Como ejercicio final, podríamos probar a enfocar el modelado como un problema de clasificación, para evaluar si ofrece mejores resultados que un problema de regresión. Lo veremos en futuros posts.</p>

            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text"></span><a href="https://sgtsteiner.github.io/" class="p-author h-card" target="_blank" rel="noopener">Antonio Méndez</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text"></span><a href="/posts/wine-quality-un-problema-de-regresion/" target="_blank" rel="noopener">https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text"></span><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></li>
            
        </ul>
    



        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2021-05-31 11:37:35 CEST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2021-05-31</text><text x="915" y="140" textLength="650" transform="scale(.1)">2021-05-31</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/&amp;text=Calidad%20del%20vino%20-%20Un%20problema%20de%20regresi%c3%b3n&amp;hashtags=regresi%c3%b3n,ExtraTrees,&amp;via=Steiner_69" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/&amp;title=Calidad%20del%20vino%20-%20Un%20problema%20de%20regresi%c3%b3n&amp;summary=En%20este%20post%20repasaremos%20las%20principales%20fases%20que%20componen%20un%20proyecto%20de%20Machine%20Learning.%0aExisten%20ocho%20pasos%20principales:%0a%20%20Encuadrar%20el%20problema%20y%20disponer%20de%20la%20visi%c3%b3n%20global.%0a%20%20Obtener%20los%20datos.%0a%20%20Explorar%20los%20datos%20para%20obtener%20ideas.&amp;source=Lords%20of%20Machine%20Learning" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://sgtsteiner.github.io/posts/wine-quality-un-problema-de-regresion/&amp;text=Calidad%20del%20vino%20-%20Un%20problema%20de%20regresi%c3%b3n" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            

            

            

            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/sgtsteiner.github.io\/posts\/wine-quality-un-problema-de-regresion\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    
        <div class="related-posts">
            <h2 class="related-title"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg></h2>
            <ul class="related-list">
                
                    <li class="related-item">
                        <a href="/posts/wine-quality-clasificacion-multiclase/" class="related-link">Calidad del vino - Clasificación multiclase</a>
                    </li>
                
            </ul>
        </div>
    



        
    
        <div class="post-tags">
            
                
                
                
                
                    
                    <a href="/tags/regresi%C3%B3n/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>regresión</a>
                
            
                
                
                
                
                    
                    <a href="/tags/extratrees/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>ExtraTrees</a>
                
            
        </div>
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
                <li class="post-nav-prev">
                    <a href="/posts/wine-quality-clasificacion-multiclase/" rel="prev">&lt; Calidad del vino - Clasificación multiclase</a>
                </li>
            
            
                <li class="post-nav-next">
                    <a href="/posts/breve-introduccion-machine-learning/" rel="next">Breve Introducción a Machine Learning &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;2021–2021&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;Antonio Méndez</div><div class="site-copyright"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="/rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="mailto:futitotal@gmail.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/SgtSteiner" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/Steiner_69" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://t.me/SgtSteiner" target="_blank" rel="external noopener" title="Telegram"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    mediumZoom(document.querySelectorAll('div.post-body img'), {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>







    </body>
</html>
