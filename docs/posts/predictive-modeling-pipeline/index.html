<!DOCTYPE html>
<html lang="es-ES">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.83.1" /><meta name="theme-color" content="#fff" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>Pipeline de modelado predictivo | Lords of the Machine Learning</title>

    <link rel="stylesheet" href="/css/meme.min.317d84c7f6754ad23a2ae219d212f73a900416875fb1144e27652ca955c5aac2.css"/>

    
    
        <script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lunr-languages@1.4.0/min/lunr.stemmer.support.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lunr-languages@1.4.0/min/lunr.es.min.js" defer></script><script src="/js/meme.min.49400d21a299355489a0a02cf7737ef1e4e5fe75fe5bd16cd756376c2bb6b749.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM&#43;Plex&#43;Serif:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Comfortaa:wght@700&amp;display=swap" /></noscript>

    <meta name="author" content="Antonio Méndez" /><meta name="description" content="En este post vamos a presentar un ejemplo de un pipeline de modelado predictivo típico usando datos tabulares, es decir, que pueden ser estructurados en una tabla de 2 dimensiones. En primer lugar, analizaremos el dataset usado y posteriormente entrenaremos un primer pipeline predictivo." />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="Lords of the Machine Learning" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="Lords of the Machine Learning" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2022-03-07T18:04:46+01:00",
        "dateModified": "2022-03-22T19:35:25+01:00",
        "url": "https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/",
        "headline": "Pipeline de modelado predictivo",
        "description": "En este post vamos a presentar un ejemplo de un pipeline de modelado predictivo típico usando datos tabulares, es decir, que pueden ser estructurados en una tabla de 2 dimensiones. En primer lugar, analizaremos el dataset usado y posteriormente entrenaremos un primer pipeline predictivo.",
        "inLanguage" : "es-ES",
        "articleSection": "posts",
        "wordCount":  8577 ,
        "image": ["https://sgtsteiner.github.io/images/output_11_0.png","https://sgtsteiner.github.io/images/output_19_1.png","https://sgtsteiner.github.io/images/output_22_0.png","https://sgtsteiner.github.io/images/output_23_0.png","https://sgtsteiner.github.io/images/model_fit.png","https://sgtsteiner.github.io/images/model_predict.png","https://sgtsteiner.github.io/images/model_score.png","https://sgtsteiner.github.io/images/transformer_transformer.png","https://sgtsteiner.github.io/images/transform_fit_transform.png","https://sgtsteiner.github.io/images/output_87_0.png","https://sgtsteiner.github.io/images/output_87_1.png","https://sgtsteiner.github.io/images/pipeline_fit.png","https://sgtsteiner.github.io/images/pipeline_predict.png","https://sgtsteiner.github.io/images/k_fold.png","https://sgtsteiner.github.io/images/column_transformer.png"],
        "author": {
            "@type": "Person",
            "description": "Sgt. Steiner",
            "email": "futitotal@gmail.com",
            "image": "https://sgtsteiner.github.io/icons/apple-touch-icon.png",
            "url": "https://sgtsteiner.github.io/",
            "name": "Antonio Méndez"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es)",
        "publisher": {
            "@type": "Organization",
            "name": "Lords of the Machine Learning",
            "logo": {
                "@type": "ImageObject",
                "url": "https://sgtsteiner.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://sgtsteiner.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://sgtsteiner.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />


<meta name="twitter:site" content="@Steiner_69" />
<meta name="twitter:creator" content="@Steiner_69" />

    



<meta property="og:title" content="Pipeline de modelado predictivo" />
<meta property="og:description" content="En este post vamos a presentar un ejemplo de un pipeline de modelado predictivo típico usando datos tabulares, es decir, que pueden ser estructurados en una tabla de 2 dimensiones. En primer lugar, analizaremos el dataset usado y posteriormente entrenaremos un primer pipeline predictivo." />
<meta property="og:url" content="https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/" />
<meta property="og:site_name" content="Lords of the Machine Learning" />
<meta property="og:locale" content="es" /><meta property="og:image" content="https://sgtsteiner.github.io/images/output_11_0.png" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2022-03-07T18:04:46&#43;01:00" />
    <meta property="article:modified_time" content="2022-03-22T19:35:25&#43;01:00" />
    
    <meta property="article:section" content="posts" />



    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">Lords of the Machine Learning</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/posts/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon archive"><path d="M32 448c0 17.7 14.3 32 32 32h384c17.7 0 32-14.3 32-32V160H32v288zm160-212c0-6.6 5.4-12 12-12h104c6.6 0 12 5.4 12 12v8c0 6.6-5.4 12-12 12H204c-6.6 0-12-5.4-12-12v-8zM480 32H32C14.3 32 0 46.3 0 64v48c0 8.8 7.2 16 16 16h480c8.8 0 16-7.2 16-16V64c0-17.7-14.3-32-32-32z"/></svg><span class="menu-item-name">Posts</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255 0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255 0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255 0-24 10.745-24 24zm386.667-56H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24z"/></svg><span class="menu-item-name">Categories</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">Tags</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">About</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
            
                <li class="menu-item search-item">
                        <form id="search" class="search" role="search">
    <label for="search-input"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon search-icon"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></label>
    <input type="search" id="search-input" class="search-input">
</form>

<template id="search-result" hidden>
    <article class="content post">
        <h2 class="post-title"><a class="summary-title-link"></a></h2>
        <summary class="summary"></summary>
        <div class="read-more-container">
            <a class="read-more-link"> »</a>
        </div>
    </article>
</template>

                    </li>
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-small-caps="true" data-align="default" data-type="posts" data-toc-num="true">

            <h1 class="post-title p-name">Pipeline de modelado predictivo</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2022-03-07T18:04:46&#43;01:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;7.3.2022</time>
    
    
        
        <time datetime="2022-03-22T19:35:25&#43;01:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;22.3.2022</time>
    
    
    
        
        
        
            
                <span class="post-meta-item category"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href="/categories/tutoriales/" class="category-link p-category">tutoriales</a></span>
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;8577</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;41&nbsp;</span>
    
    
    
</div>

            

            <div class="post-body e-content">
              <p style="text-indent:0"><span class="drop-cap">E</span>n este post vamos a presentar un ejemplo de un pipeline de modelado predictivo típico usando datos tabulares, es decir, que pueden ser estructurados en una tabla de 2 dimensiones. En primer lugar, analizaremos el dataset usado y posteriormente entrenaremos un primer pipeline predictivo. Después prestaremos atención a los tipos de datos que tiene que manejar nuestro modelo: numéricos y categóricos. Por último, extenderemos nuestro pipeline para tipos de datos mixtos, es decir, numéricos y categóricos.</p>
<p>El objetivo a conseguir es construir intuiciones respecto a un dataset desconocido, identificar y discriminar <em>features</em> numéricas y categóricas y, finalmente, crear un pipeline predictivo avanzado con <em>scikit-learn</em>.</p>
<p>En concreto mostraremos los siguientes aspectos:</p>
<ul>
<li>identificar datos númericos en un dataset heterogéneo</li>
<li>seleccionar el subconjunto de columnas correspondientes a datos numéricos</li>
<li>usar la función de scikit-learn <code>train_test_split</code> para dividir los datos en entrenamiento y prueba</li>
<li>entrenar y evaluar un modelo de regresión logística</li>
<li>la importancia de evaluar el rendimiento de generalización en los datos de prueba</li>
<li>usar un predictor dummy para obtener una línea base de referencia</li>
<li>ver la importancia de escalar las variables numéricas</li>
<li>usar un pipeline para encadenar el escalado y el entrenamiento de una regresión logística</li>
<li>evaluar el rendimiento de generalización de nuestro modelo a partir de validación cruzada</li>
<li>mostrar las dos estrategias comunes para codificar variables categóricas: <code>ordinal</code> y <code>one-hot</code></li>
<li>usar un pipeline para utilizar un codificador one-hot antes de entrenar un predictor</li>
<li>usar un <code>ColumnTransformer</code> para aplicar preprocesamientos diferentes a variables numéricas y categóricas</li>
<li>usar un pipeline para encadenar el preprocesamiento <code>ColumnTransformer</code> y entrenar una regresión logística</li>
</ul>
<h1 id="primer-vistazo-al-dataset"><a href="#primer-vistazo-al-dataset" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Primer vistazo al dataset</h1>
<p>Antes de llevar a cabo cualquier tarea de machine learning hay que realizar un serie de pasos:</p>
<ul>
<li>cargar los datos.</li>
<li>observar las variables del dataset, diferenciando entre variables numéricas y categóricas, las cuales necesitarán un preprocesamiento diferente en la mayoría de los flujos de machine learning.</li>
<li>visualizar la distribución de las variables para obtener algún tipo de conocimiento o idea del dataset.</li>
</ul>
<p>Usaremos el dataset &ldquo;<strong>credit-g</strong>&rdquo;. Para más detalles sobre dicho dataset puedes acceder al link <a href="https://www.openml.org/d/31" target="_blank" rel="noopener">https://www.openml.org/d/31</a>. El objetivo del dataset es clasificar a las personas por un conjunto de atributos como buenas o malas respecto al riesgo crediticio. Los datos están disponibles en un fichero CSV y usaremos pandas para leerlo.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">credit</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;credit-g.csv&#34;</span><span class="p">)</span></code></pre></div>
<h2 id="las-variables-del-dataset"><a href="#las-variables-del-dataset" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Las variables del dataset</h2>
<p>Los datos se almacenan en un <em>dataframe</em> de pandas. Un dataframe es una estructura de datos de 2 dimensiones. Este tipo de datos también se denominan datos tabulares.</p>
<p>Cada fila representa un &ldquo;ejemplo&rdquo;. En el ámbito de machine learning se usan normalmente los términos equivalentes de &ldquo;registro&rdquo;, &ldquo;instancia&rdquo; u &ldquo;observación&rdquo;.</p>
<p>Cada columna representa un tipo de información que ha sido recopilada y se denominan &ldquo;features&rdquo;. En el campo de machine learning es normal usar los términos equivalentes de &ldquo;variable&rdquo;, &ldquo;atributo&rdquo; o &ldquo;covariable&rdquo;.</p>
<p>Echemos un vistazo rápido al dataframe para mostrar las primeras filas:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>checking_status</th>
      <th>duration</th>
      <th>credit_history</th>
      <th>purpose</th>
      <th>credit_amount</th>
      <th>savings_status</th>
      <th>employment</th>
      <th>installment_commitment</th>
      <th>personal_status</th>
      <th>other_parties</th>
      <th>...</th>
      <th>property_magnitude</th>
      <th>age</th>
      <th>other_payment_plans</th>
      <th>housing</th>
      <th>existing_credits</th>
      <th>job</th>
      <th>num_dependents</th>
      <th>own_telephone</th>
      <th>foreign_worker</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>'&lt;0'</td>
      <td>6</td>
      <td>'critical/other existing credit'</td>
      <td>radio/tv</td>
      <td>1169</td>
      <td>'no known savings'</td>
      <td>'&gt;=7'</td>
      <td>4</td>
      <td>'male single'</td>
      <td>none</td>
      <td>...</td>
      <td>'real estate'</td>
      <td>67</td>
      <td>none</td>
      <td>own</td>
      <td>2</td>
      <td>skilled</td>
      <td>1</td>
      <td>yes</td>
      <td>yes</td>
      <td>good</td>
    </tr>
    <tr>
      <th>1</th>
      <td>'0&lt;=X&lt;200'</td>
      <td>48</td>
      <td>'existing paid'</td>
      <td>radio/tv</td>
      <td>5951</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>2</td>
      <td>'female div/dep/mar'</td>
      <td>none</td>
      <td>...</td>
      <td>'real estate'</td>
      <td>22</td>
      <td>none</td>
      <td>own</td>
      <td>1</td>
      <td>skilled</td>
      <td>1</td>
      <td>none</td>
      <td>yes</td>
      <td>bad</td>
    </tr>
    <tr>
      <th>2</th>
      <td>'no checking'</td>
      <td>12</td>
      <td>'critical/other existing credit'</td>
      <td>education</td>
      <td>2096</td>
      <td>'&lt;100'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>2</td>
      <td>'male single'</td>
      <td>none</td>
      <td>...</td>
      <td>'real estate'</td>
      <td>49</td>
      <td>none</td>
      <td>own</td>
      <td>1</td>
      <td>'unskilled resident'</td>
      <td>2</td>
      <td>none</td>
      <td>yes</td>
      <td>good</td>
    </tr>
    <tr>
      <th>3</th>
      <td>'&lt;0'</td>
      <td>42</td>
      <td>'existing paid'</td>
      <td>furniture/equipment</td>
      <td>7882</td>
      <td>'&lt;100'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>2</td>
      <td>'male single'</td>
      <td>guarantor</td>
      <td>...</td>
      <td>'life insurance'</td>
      <td>45</td>
      <td>none</td>
      <td>'for free'</td>
      <td>1</td>
      <td>skilled</td>
      <td>2</td>
      <td>none</td>
      <td>yes</td>
      <td>good</td>
    </tr>
    <tr>
      <th>4</th>
      <td>'&lt;0'</td>
      <td>24</td>
      <td>'delayed previously'</td>
      <td>'new car'</td>
      <td>4870</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>3</td>
      <td>'male single'</td>
      <td>none</td>
      <td>...</td>
      <td>'no known property'</td>
      <td>53</td>
      <td>none</td>
      <td>'for free'</td>
      <td>2</td>
      <td>skilled</td>
      <td>2</td>
      <td>none</td>
      <td>yes</td>
      <td>bad</td>
    </tr>
  </tbody>
</table></div>
<p>5 rows × 21 columns</p>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(1000, 21)
</code></pre>
<p>El dataset está compuesto de 1.000 instancias y 21 variables. La columna llamada <code>class</code> es nuestra variable objetivo (es decir, la variable que queremos predecir). Las dos posibles clases son <code>good</code> (bajo riesgo credicitio) y <code>bad</code> (alto riesgo crediticio). El problema de predicción resultante es, por tanto, un problema de clasificación binaria. Usaremos el resto de columnas como variables de entrada para nuestro modelo.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="p">[</span><span class="s2">&#34;class&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></div>
<pre><code>good    700
bad     300
Name: class, dtype: int64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="p">[</span><span class="s2">&#34;class&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span><span class="n">autopct</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%1.2f%%</span><span class="s1">&#39;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_11_0.png" alt="png"></p>
<p>Vemos que las clases están desbalanceadas, lo que significa que tenemos más instancias de una o más clases comparada con las otras. El desequilibro de clases sucede frecuentemente en la práctica y puede requerir de técnicas especiales al construir el modelo predictivo. Veremos este tipo de técnicas en otros posts.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="o">.</span><span class="n">dtypes</span></code></pre></div>
<pre><code>checking_status           object
duration                   int64
credit_history            object
purpose                   object
credit_amount              int64
savings_status            object
employment                object
installment_commitment     int64
personal_status           object
other_parties             object
residence_since            int64
property_magnitude        object
age                        int64
other_payment_plans       object
housing                   object
existing_credits           int64
job                       object
num_dependents             int64
own_telephone             object
foreign_worker            object
class                     object
dtype: object
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></div>
<pre><code>object    14
int64      7
dtype: int64
</code></pre>
<p>Comprobamos que el dataset contiene tanto datos numéricos (7 features) como categóricos (14 features, incluyendo la variable objetivo). En este caso sus tipos son <code>int64</code> y <code>object</code>, respectivamente.</p>
<h2 id="inspección-visual-de-los-datos"><a href="#inspección-visual-de-los-datos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Inspección visual de los datos</h2>
<p>Antes de construir cualquier modelo predictivo es buena idea echar un vistazo a los datos:</p>
<ul>
<li>quizás la tarea que estamos intentando conseguir se pueda resolver sin utilizar machine learning;</li>
<li>debemos comprobar que la información que necesitamos se encuentra presente realmente en el dataset;</li>
<li>inspeccionar los datos en una buena forma de encontrar peculiaridades. Estas pueden aparecer durante la recolección de los datos (por ejemplo, debido al malfuncionamiento de sensores o valores faltantes) o en la forma en que los datos son procesados posteriormente (por ejemplo, valores &ldquo;capados&rdquo;).</li>
</ul>
<p>Echemos un vistazo a las distribuciones de las features individualmente para obtener algún conocimiento adicional sobre los datos. Podemos empezar dibujando histogramas, aunque esto solo aplicaría a las features numéricas:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">_</span> <span class="o">=</span> <span class="n">credit</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span></code></pre></div>
<pre><code>C:\Program Files\Python39\lib\site-packages\pandas\plotting\_matplotlib\tools.py:400: MatplotlibDeprecationWarning: 
The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.
  if ax.is_first_col():
</code></pre>
<p><img src="/images/output_19_1.png" alt="png"></p>
<p>Algunos comentarios sobre estas variables:</p>
<ul>
<li><code>duration</code>: la mayoría de las personas a las que se les concede el crédito su duración está entre aproximadamente 4 y 24 meses, principalmente entre 12 y 24 meses.</li>
<li><code>credit_amount</code>: la mayoría de las personas solicita un crédito menor de 4.000 aproximadamente.</li>
<li><code>age</code>: la mayoría de las personas que solicitan un crédito son menores de 40 años.</li>
</ul>
<p>Veamos la distribución de algunas variables categóricas:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&#34;checking_status&#34;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">credit</span><span class="p">)</span></code></pre></div>
<p><img src="/images/output_22_0.png" alt="png"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&#34;credit_history&#34;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">credit</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&#34;right&#34;</span><span class="p">);</span></code></pre></div>
<p><img src="/images/output_23_0.png" alt="png"></p>
<p>Bueno, hasta ahora hemos visto cómo cargar un dataset, calcular su tamaño y visualizar de forma rápida las primeras filas del mismo. En un primer análisis de las variables que lo componen, hemos identificado nuestra variable objetivo y diferenciado las variables numéricas y categóricas. También hemos podido observar cómo se distribuyen sus valores.</p>
<h1 id="modelo-simple-con-scikit-learn"><a href="#modelo-simple-con-scikit-learn" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Modelo simple con scikit-learn</h1>
<p>Vamos a crear un primer modelo predictivo, para lo cual solo usaremos las variables numéricas. Los datos numéricos son el tipo de datos más natural en machine learning y (casi) pueden incorporarse directamente a los modelos predictivos.</p>
<p>Como hemos visto, el archivo CSV contiene toda la información que necesitamos: el objetivo que nos gustaría predecir (es decir, <code>class</code>) y los datos que queremos usar para entrenar nuestro modelo predictivo (es decir, las columnas restantes). El primer paso es separar las columnas para obtener de un lado el objetivo y del otro lado los datos.</p>
<h2 id="separar-los-datos-y-el-objetivo"><a href="#separar-los-datos-y-el-objetivo" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Separar los datos y el objetivo</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">target_name</span> <span class="o">=</span> <span class="s2">&#34;class&#34;</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">credit</span><span class="p">[</span><span class="n">target_name</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">credit</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_name</span><span class="p">])</span></code></pre></div>
<p>Vamos a usar una función de sklearn que nos permite seleccionar las columnas en función del tipo de dato.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_selector</span> <span class="k">as</span> <span class="n">selector</span>

<span class="n">numerical_columns_selector</span> <span class="o">=</span> <span class="n">selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>
<span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">numerical_columns_selector</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">numerical_columns</span></code></pre></div>
<pre><code>['duration',
 'credit_amount',
 'installment_commitment',
 'residence_since',
 'age',
 'existing_credits',
 'num_dependents']
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">numerical_columns</span><span class="p">]</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration</th>
      <th>credit_amount</th>
      <th>installment_commitment</th>
      <th>residence_since</th>
      <th>age</th>
      <th>existing_credits</th>
      <th>num_dependents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>1169</td>
      <td>4</td>
      <td>4</td>
      <td>67</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>48</td>
      <td>5951</td>
      <td>2</td>
      <td>2</td>
      <td>22</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12</td>
      <td>2096</td>
      <td>2</td>
      <td>3</td>
      <td>49</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42</td>
      <td>7882</td>
      <td>2</td>
      <td>4</td>
      <td>45</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24</td>
      <td>4870</td>
      <td>3</td>
      <td>4</td>
      <td>53</td>
      <td>2</td>
      <td>2</td>
    </tr>
  </tbody>
</table></div>
</div>
<h2 id="entrenar-un-modelo-y-hacer-predicciones"><a href="#entrenar-un-modelo-y-hacer-predicciones" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Entrenar un modelo y hacer predicciones</h2>
<p>Vamos a construir un modelo de clasificación usando <em>regresión logística</em>, que pertenece a la familia de los modelos lineales.</p>
<p>Brevemente, los modelos lineales buscan un conjunto de pesos para combinar linealmente las features y predecir el objetivo. Por ejemplo, el modelo puede generar un regla como la siguiente:</p>
<ul>
<li>
<p>si <code>0.1 * duration + 3.3 * credit_amount - 15.1 * installment_commitment + 3.2 * residence_since - 0.2 * age + 1.3 * existing_credits - 0.9 * num_dependents + 13.2 &gt; 0</code>, predice <code>good</code></p>
</li>
<li>
<p>en caso contrario predice <code>bad</code></p>
</li>
</ul>
<p>El metodo <code>fit</code> se llama para entrenar el modelo a partir de los datos de entrada (features) y objetivo.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s2">&#34;diagram&#34;</span><span class="p">)</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></div>
<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3adf2a4e-1762-440c-9d99-38f70c9e5d7a" type="checkbox" checked><label class="sk-toggleable__label" for="3adf2a4e-1762-440c-9d99-38f70c9e5d7a">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>
<p>El proceso de aprendizaje puede representarse de la siguiente forma:</p>
<p><img src="/images/model_fit.png" alt=""></p>
<p>El método <code>fit</code>se compone de dos elementos: un algoritmo de aprendizaje y algunos estados del modelo. El algoritmo de aprendizaje toma los datos y el objetivo de entrenamiento como entrada y establece los estados del modelo. Estos estados del modelo se utilizarán posteriormente para predecir (por clasificadores o regresores) o transformar los datos (por transformadores).</p>
<p>Tanto el algoritmo de aprendizaje como el tipo de estados del modelo son específicos para cada tipo de modelo.</p>
<p>Usaremos ahora nuestro modelo para llevar a cabo algunas predicciones usando el mismo dataset.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code></pre></div>
<p>El mecanismo de predicción puede representarse de la siguiente forma:</p>
<p><img src="/images/model_predict.png" alt=""></p>
<p>Para predecir, un modelo usa una <strong>función de predicción</strong> que utilizará los datos de entrada junto con los estados del modelo. Como el algoritmo de aprendizaje y los estados del modelo, la función de predicción es específica para cada tipo de modelo.</p>
<p>Vamos a revisar las predicciones calculadas. Por simplicidad vamos a echar un vistazo a los primeros cinco objetivos predichos.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_predicted</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>array(['good', 'bad', 'good', 'good', 'good'], dtype=object)
</code></pre>
<p>De hecho, podemos comparar estas predicciones con los datos reales:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>0    good
1     bad
2    good
3    good
4     bad
Name: class, dtype: object
</code></pre>
<p>e incluso podríamos comprobar si las predicciones concuerdan con los objetivos reales:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_predicted</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>0     True
1     True
2     True
3     True
4    False
Name: class, dtype: bool
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Nº de predicciones correctas: {(y_predicted[:5] == y[:5]).sum()} de las 5 primeras&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>Nº de predicciones correctas: 4 de las 5 primeras
</code></pre>
<p>En este caso, parece que nuestro modelo comete un error al predecir la quinta instancia. Para obtener un mejor evaluación podemos calcular la tasa promedio de éxito:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">(</span><span class="n">y_predicted</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></code></pre></div>
<pre><code>0.706
</code></pre>
<p>¿Podemos confiar en esta evaluación? ¿Es buena o mala?</p>
<h2 id="división-de-los-datos-en-entrenamiento-y-prueba"><a href="#división-de-los-datos-en-entrenamiento-y-prueba" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>División de los datos en entrenamiento y prueba</h2>
<p>Cuando construimos un modelo de machine learning es muy importante evaluar el modelo entrenado en datos que no se hayan usado para entrenarlo, ya que la <strong>generalización</strong> es más que la memorización (significa que queremos una regla que generalice a nuevos datos, sin comparar los datos memorizados). Es más difícil concluir sobre datos nunca vistos que sobre los ya vistos.</p>
<p>La evaluación correcta se realiza fácilmente reservando un subconjunto de los datos cuando entrenamos el modelo y usándolos posteriormente para evaluar el modelo. Los datos usados para entrenar un modelo se denominan <strong>datos de entrenamiento</strong> mientras que los datos usados para evaluar el modelo se denominan <strong>datos de prueba</strong>.</p>
<p>En ocasiones podemos contar con dos datasets separados, uno para el entrenamiento y otro para pruebas. Sin embargo, esto suele ser bastante inusual. La mayoría de las veces tendremos un único archivo que contiene todos los datos y necesitaremos dividirlo una vez cargado en memoria.</p>
<p>Scikit-learn proporciona la función <code>sklearn.model_selection.train_test_split</code>, que usaremos para dividir automáticamente el dataset en dos subconjuntos.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span></code></pre></div>
<p>Cuando llamamos a la función <code>train_test_split</code>, especificamos que queremos tener el 20% de las instancias en el conjunto de prueba y las instancias restantes (80%) estarán disponibles para el conjunto de entrenamiento.</p>
<h2 id="establecimiento-de-una-línea-base"><a href="#establecimiento-de-una-línea-base" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Establecimiento de una línea base</h2>
<p>Para avaluar el rendimiento de nuestro modelo predictivo resulta de utilidad establecer una línea base simple. La línea base más simple para un clasificador es aquella que predice siempre la misma clase, independientemente de los datos de entrada. Para ello usaremos un <code>DummyClassifier</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>

<span class="n">clf_dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&#34;most_frequent&#34;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">clf_dummy</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">accuracy_dummy</span> <span class="o">=</span> <span class="n">clf_dummy</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Accuracy línea base: {accuracy_dummy}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>Accuracy línea base: 0.705
</code></pre>
<p>Este clasificador dummy predice siempre la clase más frecuente (en nuestro caso, la clase <code>good</code>). Como vimos anteriormente la proporción de clase <code>good</code> era del 70%, que coincide con la puntuación obtenida por este clasificador. Bien, ya tenemos una linea base con la que comparar nuestro modelo.</p>
<p>Vamos a entrenar el modelo exactamente de la misma forma que vimos anteriormente, excepto que usaremos para ello los subconjuntos de entrenamiento:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="267eb83a-ee9c-4987-aaa9-d47be04cff2b" type="checkbox" checked><label class="sk-toggleable__label" for="267eb83a-ee9c-4987-aaa9-d47be04cff2b">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>
<p>En lugar de calcular la predicción y calcular manualmente la tasa media de éxito, podemos usar el método <code>score</code>. Cuando se trata de clasificadores este método devuelve su métrica de rendimiento.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">accuracy_lgr</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Accuracy: {accuracy_lgr:.3f}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>Accuracy: 0.740
</code></pre>
<p>Veamos el mecanismo subyacente cuando se llama al método <code>score</code>:</p>
<p><img src="/images/model_score.png" alt=""></p>
<p>Para calcular la puntuación, el predictor primero calcula las predicciones (usando el metodo <code>predict</code>) y luego usa una función de puntuación para comparar los objetivos reales y las predicciones. Por último, se devuelve la puntuación.</p>
<p>Por norma general, nos referimos al <strong>rendimiento de generalización</strong> de un modelo cuando nos refiramos a la puntuación de prueba o al error de prueba obtenido al comparar la predicción de un modelo con los objetivos reales. También son términos equivalentes rendimiento predictivo y rendimiento estadístico. Nos referimos al <strong>rendimiento computacional</strong> de un modelo predictivo cuando accedemos al coste computacional de entrenar un modelo predictivo o usarlo para hacer predicciones.</p>
<p>Bueno, la puntuación de nuestro modelo apenas mejora la linea base que establecimos:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Accuracy línea base = {accuracy_dummy}&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Accuracy regresión logística = {accuracy_lgr}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>Accuracy línea base = 0.705
Accuracy regresión logística = 0.74
</code></pre>
<p>Seguro que podemos hacerlo mejor. Veamos cómo.</p>
<h1 id="preprocesamiento-de-features-numéricas"><a href="#preprocesamiento-de-features-numéricas" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Preprocesamiento de features numéricas</h1>
<p>En los siguientes apartados vamos a introducir el uso del preprocesamiento, en este caso del <strong>escalado de variables numéricas</strong>; y del uso de un pipeline para encadenar el preprocesamiento y el entrenamiento del modelo.</p>
<p>Scikit-learn cuenta con una amplia gama de algoritmos de preprocesamiento que nos permiten transformar los datos de entrada antes de entrenar un modelo. Es este caso, vamos a estandarizar los datos y después entrenaremos un nuevo modelo de regresión logística es esta nueva versión del dataset.</p>
<p>En primer lugar, vamos a mostrar algunas estadísticas sobre los datos de entrenamiento.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration</th>
      <th>credit_amount</th>
      <th>installment_commitment</th>
      <th>residence_since</th>
      <th>age</th>
      <th>existing_credits</th>
      <th>num_dependents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>800.000000</td>
      <td>800.000000</td>
      <td>800.000000</td>
      <td>800.000000</td>
      <td>800.000000</td>
      <td>800.000000</td>
      <td>800.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>21.095000</td>
      <td>3360.618750</td>
      <td>2.965000</td>
      <td>2.846250</td>
      <td>35.558750</td>
      <td>1.411250</td>
      <td>1.143750</td>
    </tr>
    <tr>
      <th>std</th>
      <td>11.807211</td>
      <td>2898.174863</td>
      <td>1.122653</td>
      <td>1.105277</td>
      <td>11.411587</td>
      <td>0.578828</td>
      <td>0.351056</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.000000</td>
      <td>250.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>19.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>12.000000</td>
      <td>1380.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>27.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>18.000000</td>
      <td>2333.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>33.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>24.000000</td>
      <td>4154.500000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>42.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>60.000000</td>
      <td>18424.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>75.000000</td>
      <td>4.000000</td>
      <td>2.000000</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>Observamos que las features del dataset abarcan diferentes rangos. Algunos algoritmos hacen suposiciones con respecto a las distribuciones de las features y, en general, la normalización de estas features resultará de utilidad para abordar estas suposiciones. Algunas razones para el escalado de features son las siguientes:</p>
<ul>
<li>
<p>Los modelos basados en distancias entre pares de instancias, por ejemplo, k-nearest neighbors, deben ser entrenados con features normalizadas para hacer que cada feature contribuya aproximadamente por igual a los cálculos de distancias.</p>
</li>
<li>
<p>Muchos modelos, como la regresión logística usan solucionadores numéricos (basados en descenso de gradiente) para encontrar sus parámetros óptimos. Este solucionador converge más rápido cuando las features están escaladas.</p>
</li>
</ul>
<p>El hecho de que un modelo de machile learning requiera o no de escalado de features depende de la familia del modelo. Los modelos lineales como la regresión logística generalmente se benefician del escalado mientras que otros modelos como los árboles de decisión no necesitan de este preprocesado (pero tampoco se verían penalizados).</p>
<p>Vamos a mostrar cómo aplicar tal normalización usando un transformador de scikit-learn llamado <code>StandardScaler</code>. Este transformador escala cada feature individualmente para que todas tengan media 0 y desviación estándar 1. Analizaremos los diferentes pasos usados por scikit-learn para conseguir esta transformación de los datos.</p>
<p>Lo primero que necesitamos es llamar al método <code>fit</code> para que aprenda el escalado de los datos.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span></code></pre></div>
<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="9d5ca8dc-9cdd-4344-adca-3f5a0c2964bd" type="checkbox" checked><label class="sk-toggleable__label" for="9d5ca8dc-9cdd-4344-adca-3f5a0c2964bd">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div>
<p>El método <code>fit</code> de los transformadores es similar al método <code>fit</code> de los predictores. La diferencia principal es que el transformador tiene un único argumento, la matriz de datos, mientras que el último tiene dos argumentos, la matriz de datos y el objetivo. En este caso, el algoritmo necesita calcular la media y la desviación típica de cada feature y almacenarla en algunas arrays de Numpy. Aquí, estos estadísticos son los estados del modelo. El hecho de que los estados del modelo de este scaler sean arrays de medias y desviaciones típicas es específico del <code>StandardScale</code>. Otros transformadores de scikit-learn calcularán diferentes estadísticos y los almacenarán como estados del modelo de la misma forma.</p>
<p>Vamos a inspeccionar las medias y desviaciones típicas calculadas.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scaler</span><span class="o">.</span><span class="n">mean_</span></code></pre></div>
<pre><code>array([2.10950000e+01, 3.36061875e+03, 2.96500000e+00, 2.84625000e+00,
       3.55587500e+01, 1.41125000e+00, 1.14375000e+00])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scaler</span><span class="o">.</span><span class="n">scale_</span></code></pre></div>
<pre><code>array([1.17998294e+01, 2.89636294e+03, 1.12195142e+00, 1.10458632e+00,
       1.14044530e+01, 5.78466453e-01, 3.50836055e-01])
</code></pre>
<p>Ya sabemos, por convención de scikit-learn, que si un atributo aprende de los datos, su nombre termina con <code>_</code>, como <code>mean_</code> y <code>scale_</code> para el <code>StandardScaler</code>.</p>
<p>El escalado de los datos se aplica a cada feature de forma individual. Para cada feature, restamos su media y dividimos por su desviación típica. Una vez que hemos llamado al método <code>fit</code> podemos ejecutar la transformación llamando al método <code>transform</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_scaled</span></code></pre></div>
<pre><code>array([[ 3.29708155,  1.19991221,  0.03119565, ...,  2.4061873 ,
         1.01777726, -0.40973554],
       [-0.00805096, -0.35962991, -0.86010854, ..., -0.22436411,
        -0.71093146, -0.40973554],
       [-1.27925578, -0.73354714, -0.86010854, ...,  1.26628169,
        -0.71093146, -0.40973554],
       ...,
       [ 0.24619   ,  0.84360327,  0.92249983, ..., -0.7504744 ,
         1.01777726, -0.40973554],
       [-0.77077385, -0.64792251, -0.86010854, ..., -0.92584449,
        -0.71093146, -0.40973554],
       [-1.27925578, -0.83850636,  0.03119565, ..., -1.01352954,
        -0.71093146, -0.40973554]])
</code></pre>
<p>Vamos a analizar el mecanismo interno del método <code>transform</code> y lo pondremos en perspectiva con lo que ya vimos con los predictores.</p>
<p><img src="/images/transformer_transformer.png" alt=""></p>
<p>El método <code>transform</code> para los transformadores es similar al método <code>predict</code> para los predictores. Usa una función predefinida, llamada <strong>función de transformación</strong>, y usa los estados del modelo y los datos de entrada. Sin embargo, en lugar de devolver predicciones, el trabajo del método <code>transform</code> es devolver una versión transformada de los datos de entrada.</p>
<p>Por último, el método <code>fit_transform</code> es un método abreviado para llamar sucesivamente a <code>fit</code>y después a <code>transform</code>.</p>
<p><img src="/images/transform_fit_transform.png" alt=""></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_scaled</span></code></pre></div>
<pre><code>array([[ 3.29708155,  1.19991221,  0.03119565, ...,  2.4061873 ,
         1.01777726, -0.40973554],
       [-0.00805096, -0.35962991, -0.86010854, ..., -0.22436411,
        -0.71093146, -0.40973554],
       [-1.27925578, -0.73354714, -0.86010854, ...,  1.26628169,
        -0.71093146, -0.40973554],
       ...,
       [ 0.24619   ,  0.84360327,  0.92249983, ..., -0.7504744 ,
         1.01777726, -0.40973554],
       [-0.77077385, -0.64792251, -0.86010854, ..., -0.92584449,
        -0.71093146, -0.40973554],
       [-1.27925578, -0.83850636,  0.03119565, ..., -1.01352954,
        -0.71093146, -0.40973554]])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span>
                              <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X_train_scaled</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>duration</th>
      <th>credit_amount</th>
      <th>installment_commitment</th>
      <th>residence_since</th>
      <th>age</th>
      <th>existing_credits</th>
      <th>num_dependents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
      <td>8.000000e+02</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>9.769963e-17</td>
      <td>-1.776357e-17</td>
      <td>1.465494e-16</td>
      <td>2.664535e-17</td>
      <td>-3.075318e-16</td>
      <td>2.242651e-16</td>
      <td>-8.437695e-17</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
      <td>1.000626e+00</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-1.448750e+00</td>
      <td>-1.073974e+00</td>
      <td>-1.751413e+00</td>
      <td>-1.671440e+00</td>
      <td>-1.451955e+00</td>
      <td>-7.109315e-01</td>
      <td>-4.097355e-01</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-7.707739e-01</td>
      <td>-6.838296e-01</td>
      <td>-8.601085e-01</td>
      <td>-7.661239e-01</td>
      <td>-7.504744e-01</td>
      <td>-7.109315e-01</td>
      <td>-4.097355e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-2.622919e-01</td>
      <td>-3.547963e-01</td>
      <td>3.119565e-02</td>
      <td>1.391924e-01</td>
      <td>-2.243641e-01</td>
      <td>-7.109315e-01</td>
      <td>-4.097355e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.461900e-01</td>
      <td>2.740959e-01</td>
      <td>9.224998e-01</td>
      <td>1.044509e+00</td>
      <td>5.648013e-01</td>
      <td>1.017777e+00</td>
      <td>-4.097355e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.297082e+00</td>
      <td>5.200792e+00</td>
      <td>9.224998e-01</td>
      <td>1.044509e+00</td>
      <td>3.458408e+00</td>
      <td>4.475195e+00</td>
      <td>2.440599e+00</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>Observemos que la media de todas las columnas es cercana a 0 y la desviación típica en todos los casos es cercano a 1. Podemos visualizar el efecto de <code>StandarScaler</code> usando un joinplot para mostrar ambos histogramas de distribución y un scatterplot de cada par de features numéricas al mismo tiempo. Observamos que <code>StandardScaler</code> no cambia la estructura de los datos en si mismos sino que los ejes han sido desplazados y escalados.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span>  <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># number of points to visualize to have a clearer plot</span>
<span class="n">num_points_to_plot</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:</span><span class="n">num_points_to_plot</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;age&#34;</span><span class="p">,</span>
              <span class="n">y</span><span class="o">=</span><span class="s2">&#34;credit_amount&#34;</span><span class="p">,</span> <span class="n">marginal_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&#34;Jointplot de &#39;age&#39; vs &#39;credit_amount&#39; </span><span class="se">\n</span><span class="s2">antes de StandardScaler&#34;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">[:</span><span class="n">num_points_to_plot</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;age&#34;</span><span class="p">,</span>
              <span class="n">y</span><span class="o">=</span><span class="s2">&#34;credit_amount&#34;</span><span class="p">,</span> <span class="n">marginal_kws</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&#34;Jointplot de &#39;age&#39; vs &#39;credit_amount&#39; </span><span class="se">\n</span><span class="s2">después de StandardScaler&#34;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span></code></pre></div>
<p><img src="/images/output_87_0.png" alt="png"></p>
<p><img src="/images/output_87_1.png" alt="png"></p>
<p>Podemos combinar fácilmente operaciones secuenciales con un <code>pipeline</code> de scikit-learn, que encadena juntas operaciones y se usa como cualquier otro clasificador o regresor. La función <code>make_pipeline</code> creará un <code>Pipeline</code>: toma como argumentos las sucesivas transformaciones a ejecutar, seguido por el modelo clasificador o regresor.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">model</span></code></pre></div>
<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="be71bd42-d445-483e-be89-885d39a54527" type="checkbox" ><label class="sk-toggleable__label" for="be71bd42-d445-483e-be89-885d39a54527">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),('logisticregression', LogisticRegression())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="8d859484-a933-41a0-9166-7e42f1304392" type="checkbox" ><label class="sk-toggleable__label" for="8d859484-a933-41a0-9166-7e42f1304392">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="2770c1bf-a52a-4dd4-b674-8382c7cdd256" type="checkbox" ><label class="sk-toggleable__label" for="2770c1bf-a52a-4dd4-b674-8382c7cdd256">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>
<p>La función <code>make_pipeline</code> no requiere que demos un nombre a cada paso. De hecho, se lo asigna automáticamente basado en el nombre de la clase suministrada; un <code>StandardScaler</code> tendrá un paso llamado <code>&quot;standardscaler&quot;</code> en el pipeline resultante. Podemos comprobar el nombre de cada paso del modelo:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">named_steps</span></code></pre></div>
<pre><code>{'standardscaler': StandardScaler(),
 'logisticregression': LogisticRegression()}
</code></pre>
<p>Este pipeline predictivo expone los mismos métodos que el predictor final: <code>fit</code> y <code>predict</code> (y adicionalmente <code>predict_proba</code>, <code>decision_function</code> o <code>score</code>).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span></code></pre></div>
<p><img src="/images/pipeline_fit.png" alt=""></p>
<p>Cuando llamamos a <code>model.fit</code>, se llamará al método <code>fit_transform</code> para cada transformador subyacente (en este caso, un único transformador) para:</p>
<ul>
<li>aprender sus estados de modelo internos</li>
<li>transformar los datos de entrenamiento. Finalmente, los datos preprocesados se suministrarán para entrenar el predictor.</li>
</ul>
<p>Para predecir los objetivos dado un conjunto de prueba se usa el método <code>predict</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_predicted</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>array(['good', 'good', 'good', 'good', 'good'], dtype=object)
</code></pre>
<p>Mostremos el mecanismo subyacente:</p>
<p><img src="/images/pipeline_predict.png" alt=""></p>
<p>Se llama al método <code>transform</code> de cada transformador (en este caso, un único transformador) para preprocesar los datos. Tengamos en cuenta que no es necesario llamar al método <code>fit</code> de esos transformadores porque estamos usando los estados de modelo internos calculados cuando llamamos a <code>model.fil</code>. Los datos preprocesados son entonces proporcionados al predictor que devolverá los objetivos predichos llamando al método <code>predict</code>.</p>
<p>Como atajo, podemos comprobar la puntuación del pipeline predictivo completo llamando al método <code>model.score</code>. Por tanto, vamos a verificar el rendimiento computacional y de generalización de este pipeline predictivo.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;La precisión usando un {model_name} es {score:.3f} &#34;</span>
      <span class="n">f</span><span class="s2">&#34;con un tiempo de entrenamiento de {elapsed_time:.3f} segundos &#34;</span>
      <span class="n">f</span><span class="s2">&#34;en {model[-1].n_iter_[0]} iteraciones&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>La precisión usando un Pipeline es 0.730 con un tiempo de entrenamiento de 0.009 segundos en 10 iteraciones
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;La precisión usando {model_name} es {score:.3f} &#34;</span>
      <span class="n">f</span><span class="s2">&#34;con un tiempo de entrenamiento de {elapsed_time:.3f} segundos &#34;</span>
      <span class="n">f</span><span class="s2">&#34;en {model.n_iter_[0]} iteraciones&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>La precisión usando LogisticRegression es 0.740 con un tiempo de entrenamiento de 0.025 segundos en 88 iteraciones
</code></pre>
<p>Vemos que escalar los datos antes de entrenar la regresión logística fue beneficioso en términos de rendimiento computacional. De hecho, el número de iteraciones decrece así como el tiempo de entrenamiento. El rendimiento de generalización no cambió dado que ambos modelos comvergen.</p>
<p>Trabajar con datos no escalados forzará potencialmente al algoritmo a iterar más como hemos visto. También existe el escenario catastrófico donde el número de iteraciones requeridas sea mayor que el número de iteraciones permitidas por el parámetro del predictor (controlado por <code>max_iter</code>). Por lo tanto, antes de incrementar <code>max_iter</code>, asegurémosnos de que los datos están escalados.</p>
<h1 id="evaluación-del-modelo-usando-validación-cruzada"><a href="#evaluación-del-modelo-usando-validación-cruzada" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Evaluación del modelo usando validación cruzada</h1>
<p>Vamos a discutir algunos aspectos prácticos de evaluar el rendimiento de generalización de nuestro modelo a través de la validación cruzada, en lugar de usar una única división entrenamiento-prueba.</p>
<h2 id="la-necesidad-de-validación-cruzada"><a href="#la-necesidad-de-validación-cruzada" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>La necesidad de validación cruzada</h2>
<p>Anteriormente dividimos los datos originales en un conjunto de entrenamiento y en un conjunto de pruebas. En general, la puntuación de un modelo dependerá de la forma en que hacemos esta división. Un inconveniente de hacer una única división es que no proporciona ninguna información sobre su variablidad. Otro inconveniente, en una configuración donde la cantidad de datos es pequeña, es que la cantidad de datos disponibles para entrenamiento y prueba será incluso más pequeña después de la división.</p>
<p>En su lugar, podemos usar validación cruzada. La validación cruzada consiste en repetir el procedimiento de modo que los conjuntos de entrenamiento y prueba sean diferentes cada vez. Las métricas de rendimiento de generalización se recopilan en cada repetición y luego se agregan. Como resultado, podemos evaluar la variabilidad de nuestra medida del rendimiento de generalización del modelo.</p>
<p>Existen varias estrategias de validación cruzada, cada una de ellas define cómo repetir el procedimiento de <code>fit</code> / <code>score</code>. En nuestro caso, usaremos la estrategia K-fold: el dataset completo se divide en <code>K</code> particiones. El procesimiento <code>fit</code> / <code>score</code> se repite <code>K</code> veces, donde en cada iteración se usan <code>K-1</code> particiones para entrenar el modelo y <code>1</code> partición para prueba. El siguiente diagrama muestra esta estrategia de K-fold.</p>
<p><img src="/images/k_fold.png" alt=""></p>
<p>El diagrama muestra el caso particular de <strong>K-fold</strong>. Para cada división de validación cruzada, el procedimiento entrena un clon del modelo en todas las instancias rojas y evalúa la puntuación del modelo en las instancias azules.</p>
<p>La validación cruzada es, por tanto, computacionalmente intensiva porque requiere entrenar varios modelos, en lugar de uno solo. En scikit-learn, la función <code>cross_validate</code> permite hacer validación cruzada y necesitamos pasar el modelo, los datos y el objetivo. Dado que existen varias estrategias, <code>cross_validate</code> toma un parámetro <code>cv</code> que define la estrategia de división.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%%</span><span class="n">time</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">cv_result</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv_result</span></code></pre></div>
<pre><code>Wall time: 50.5 ms





{'fit_time': array([0.00750613, 0.00700498, 0.00700617, 0.00750685, 0.00700593]),
 'score_time': array([0.002002  , 0.00150108, 0.00200152, 0.00200224, 0.00150156]),
 'test_score': array([0.715, 0.71 , 0.69 , 0.715, 0.735])}
</code></pre>
<p>La salida de <code>cross_validate</code> es un diccionario de Python, que contiene tres entradas por defecto:</p>
<ul>
<li>el tiempo de entrenamiento del modelo en los datos de entrenamiento en cada una de las particiones</li>
<li>el tiempo de predicción con el modelo en los datos de prueba en cada una de las particiones</li>
<li>la puntuación por defecto en los datos de prueba en cada una de las particiones</li>
</ul>
<p>Establecer <code>cv=5</code> crea 5 divisiones distintas para obtener 5 variaciones distintas para los conjuntos de entrenamiento y prueba. Cada conjunto de entrenamiento se usa para entrenar un modelo que después se evalúa en el conjunto de prueba. La estrategia por defecto cuando se establece <code>cv=int</code> es la validación cruzada K-fold, donde <code>K</code> corresponde al número (entero) de divisiones. Establecer <code>cv=5</code> o <code>cv=10</code> es una práctica común, ya que mantiene un equilibrio entre el tiempo de cálculo y la estabilidad de la variabilidad estimada.</p>
<p>Hay que tener en cuenta que la función <code>cross-validate</code>, por defecto, descarta los <code>K</code> modelos que se entrenaron en los diferentes subconjuntos superpuestos del dataset. El objetivo de la validación cruzada no es entrenar un modelo sino estimar aproximadamente el rendimiento de generalización de un modelo que se habría entrenado en el conjunto completo de entrenamiento, junto con una estimación de la variabilidad (incertidumbre sobre la precisión de la generalización).</p>
<p>Podemos pasar parámetros adiciones a <code>sklearn.mode_selection.cross_validate</code> para recopilar información adicional, tales como las puntuaciones de entrenamiento de los modelos obtenidos en cada ciclo o incluso devolver los propios modelos en lugar de descartarlos.</p>
<p>Vamos a extraer las puntuaciones calculadas en las particiones de prueba de cada ciclo de validación cruzada a partir del diccionario <code>cv_result</code> y calcular la precisión media y la variación de la precisión a lo largo de las particiones.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scores</span> <span class="o">=</span> <span class="n">cv_result</span><span class="p">[</span><span class="s2">&#34;test_score&#34;</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span>
    <span class="s2">&#34;La precisión media de validación cruzada es: &#34;</span>
    <span class="n">f</span><span class="s2">&#34;{scores.mean():.3f} +/- {scores.std():.3f}&#34;</span>
<span class="p">)</span></code></pre></div>
<pre><code>La precisión media de validación cruzada es: 0.713 +/- 0.014
</code></pre>
<p>Hay que tener en cuenta que al calcular la desviación típica de las puntuaciones de validación cruzada, podemos estimar la incertidumbre del rendimiento de generalización de nuestro modelo. Esta es la principal ventaja de la validación cruzada y puede ser crucial en la práctica, por ejemplo cuando comparamos diferentes modelos para averiguar  cuál de ellos es mejor que los demás o si nuestras medidas del rendimiento de generalización de cada modelo están dentro de las barras de error de uno u otro.</p>
<h1 id="codificación-de-variables-categóricas"><a href="#codificación-de-variables-categóricas" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Codificación de variables categóricas</h1>
<p>Bien, hasta ahora hemos visto cómo manejarnos con variables numéricas y codificarlas. Vamos a ver cómo codificar variables categóricas usando codificación <strong>ordinal</strong> y <strong>one-hot</strong>.</p>
<p>Ya vimos anteriormente que una variable numérica es una cantidad representada por un número entero o real. Estas variables se manejan de forma natural por los algoritmos de machine learning, que generalmente se componen de una secuencia de instrucciones aritméticas, como sumas y multiplicaciones.</p>
<p>Por el contrario, las variables categóricas están representadas normalmente por etiquetas de texto (pero no solo) tomadas de entre una lista finita de opciones posibles. Por ejemplo, la variable <code>personal_status</code> de nuestro dataset es una variable categórica porque codifica los datos usando una lista finita de posibles estados:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="p">[</span><span class="s2">&#34;personal_status&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></div>
<pre><code>'male single'           548
'female div/dep/mar'    310
'male mar/wid'           92
'male div/sep'           50
Name: personal_status, dtype: int64
</code></pre>
<p>¿Cómo podemos reconocer las columnas categóricas dentro del dataset? Una parte de la respuesta tiene que ver con el tipo de dato de las columnas:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">credit</span><span class="o">.</span><span class="n">dtypes</span></code></pre></div>
<pre><code>checking_status           object
duration                   int64
credit_history            object
purpose                   object
credit_amount              int64
savings_status            object
employment                object
installment_commitment     int64
personal_status           object
other_parties             object
residence_since            int64
property_magnitude        object
age                        int64
other_payment_plans       object
housing                   object
existing_credits           int64
job                       object
num_dependents             int64
own_telephone             object
foreign_worker            object
class                     object
dtype: object
</code></pre>
<p>Si observamos la columna <code>personal_status</code> podemos comprobar que su tipo de dato es <code>object</code>, lo que significar que contiene valores de texto.</p>
<h2 id="seleccionar-features-en-función-de-su-tipo-de-dato"><a href="#seleccionar-features-en-función-de-su-tipo-de-dato" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Seleccionar features en función de su tipo de dato</h2>
<p>Para seleccionar columnas basadas en su tipo de dato podemos usar la función <code>make_column_selector</code> de scikit-learn, como vimos anteriormente.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">target_name</span> <span class="o">=</span> <span class="s2">&#34;class&#34;</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">credit</span><span class="p">[</span><span class="n">target_name</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">credit</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_name</span><span class="p">])</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">categorical_columns_selector</span> <span class="o">=</span> <span class="n">selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
<span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">categorical_columns_selector</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">categorical_columns</span></code></pre></div>
<pre><code>['checking_status',
 'credit_history',
 'purpose',
 'savings_status',
 'employment',
 'personal_status',
 'other_parties',
 'property_magnitude',
 'other_payment_plans',
 'housing',
 'job',
 'own_telephone',
 'foreign_worker']
</code></pre>
<p>Hemos creado el selector pasándole el tipo de datos que queremos incluir; hemos pasado el dataset de entrada al objeto selector, que devuelve una listado de nombres de columnas que tienen el tipo de datos requerido. Ahora podemos filtrar las columnas que no queremos:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">]</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>checking_status</th>
      <th>credit_history</th>
      <th>purpose</th>
      <th>savings_status</th>
      <th>employment</th>
      <th>personal_status</th>
      <th>other_parties</th>
      <th>property_magnitude</th>
      <th>other_payment_plans</th>
      <th>housing</th>
      <th>job</th>
      <th>own_telephone</th>
      <th>foreign_worker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>'&lt;0'</td>
      <td>'critical/other existing credit'</td>
      <td>radio/tv</td>
      <td>'no known savings'</td>
      <td>'&gt;=7'</td>
      <td>'male single'</td>
      <td>none</td>
      <td>'real estate'</td>
      <td>none</td>
      <td>own</td>
      <td>skilled</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>'0&lt;=X&lt;200'</td>
      <td>'existing paid'</td>
      <td>radio/tv</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>'female div/dep/mar'</td>
      <td>none</td>
      <td>'real estate'</td>
      <td>none</td>
      <td>own</td>
      <td>skilled</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>'no checking'</td>
      <td>'critical/other existing credit'</td>
      <td>education</td>
      <td>'&lt;100'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>'male single'</td>
      <td>none</td>
      <td>'real estate'</td>
      <td>none</td>
      <td>own</td>
      <td>'unskilled resident'</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>'&lt;0'</td>
      <td>'existing paid'</td>
      <td>furniture/equipment</td>
      <td>'&lt;100'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>'male single'</td>
      <td>guarantor</td>
      <td>'life insurance'</td>
      <td>none</td>
      <td>'for free'</td>
      <td>skilled</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>'&lt;0'</td>
      <td>'delayed previously'</td>
      <td>'new car'</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>'male single'</td>
      <td>none</td>
      <td>'no known property'</td>
      <td>none</td>
      <td>'for free'</td>
      <td>skilled</td>
      <td>none</td>
      <td>yes</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>Vamos a presentar diferentes estrategias de codificación de datos categóricos a datos numéricos que puedan ser usados por un algoritmo de machine learning.</p>
<h2 id="estrategias-para-codificar-categorías"><a href="#estrategias-para-codificar-categorías" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Estrategias para codificar categorías</h2>
<h3 id="codificando-categorías-ordinales"><a href="#codificando-categorías-ordinales" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Codificando categorías ordinales</h3>
<p>La estrategia más intuitiva es codificar cada categoría con un número diferente. <code>OrdinalEncoder</code> transforma los datos de esta forma. Empezaremos codificando una única columna para comprender cómo funciona:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>

<span class="n">personal_status_column</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s2">&#34;personal_status&#34;</span><span class="p">]]</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">personal_status_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">personal_status_column</span><span class="p">)</span>
<span class="n">personal_status_encoded</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span></code></pre></div>
<pre><code>array([[3.],
       [0.],
       [3.],
       [3.],
       [3.],
       [3.],
       [3.],
       [3.],
       [1.],
       [2.]])
</code></pre>
<p>Vemos que cada categoría de <code>personal_status</code> ha sido reemplazada por un valor numérico. Podemos comprobar el mapeo entre las categorías y los valoras numéricos comprobando el atributo entrenado <code>categories_</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">encoder</span><span class="o">.</span><span class="n">categories_</span></code></pre></div>
<pre><code>[array([&quot;'female div/dep/mar'&quot;, &quot;'male div/sep'&quot;, &quot;'male mar/wid'&quot;,
        &quot;'male single'&quot;], dtype=object)]
</code></pre>
<p>Ahora podemos comprobar la codificación aplicada en todas las categorías.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_encoded</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>array([[1., 1., 7., 4., 3., 3., 2., 2., 1., 1., 3., 1., 1.],
       [0., 3., 7., 2., 0., 0., 2., 2., 1., 1., 3., 0., 1.],
       [3., 1., 4., 2., 1., 3., 2., 2., 1., 1., 2., 0., 1.],
       [1., 3., 5., 2., 1., 3., 1., 0., 1., 0., 3., 0., 1.],
       [1., 2., 1., 2., 0., 3., 2., 1., 1., 0., 3., 0., 1.]])
</code></pre>
<p>Vemos que todas las categorías se han codificado en cada feature (columna) de forma independiente. También podemos comprobar que el número de features antes y después de la codificación sigue siendo el mismo.</p>
<p>Sin embargo, debemos ser cuidadosos cuando apliquemos esta estrategia de codificación: usar esta representación de enteros conduce a los modelos predictivos posteriores a asumir que los valores están ordenados (es decir, 0 &lt; 1 &lt; 2 &lt; 3 &hellip;).</p>
<p>Por defecto, <code>OrdinalEncoder</code> usa una estrategia lexicográfica para mapear etiquetas categóricas de texto a enteros. Esta estrategia es arbitraria y a menudo sin sentido. Por ejemplo, supongamos que el dataset tiene una variable categórica llamada <code>size</code> con categorías como &ldquo;S&rdquo;, &ldquo;M&rdquo;, &ldquo;L&rdquo; y &ldquo;XL&rdquo;. Nos gustaría que la representación numérica respetase el significado de los tamaños mapeandolos incrementalmente con enteros, tal que <code>0, 1, 2, 3</code>. Sin embargo, la estrategia lexicográfica usada por defecto podría mapear las etiquetas &ldquo;S&rdquo;, &ldquo;M&rdquo;, &ldquo;L&rdquo;, &ldquo;XL&rdquo; como 2, 1, 0, 3, siguiendo un orden alfabético.</p>
<p>La clase <code>OrdinalEncoder</code> acepta un argumento constructor <code>categories</code> para pasar explícitamente las categorías en el orden esperado.</p>
<p>Si una variable categórica no contiene ninguna información significativa de orden esta codificación podría se engañosa para los modelos estadísticos posteriores y deberíamos considerar una codificación one-hot en su lugar.</p>
<h3 id="codificando-categorías-nominales-sin-asumir-ningún-orden"><a href="#codificando-categorías-nominales-sin-asumir-ningún-orden" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Codificando categorías nominales (sin asumir ningún orden)</h3>
<p><code>OneHotEncoder</code> es un codificador alternativo que previene que los modelos posteriores hagan una falsa asunción sobre el orden de las categorías. Para una feature dada, crea tantas columnas como categorías posibles. Para una instancia dada, el valor de la columna correspondiente a la categoría se establecerá a <code>1</code> mientras que las columnas de las otras categorías se establecerán a <code>0</code>.</p>
<p>Empecemos codificando una única feature (por ejemplo <code>personal_status</code>):</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">personal_status_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">personal_status_column</span><span class="p">)</span>
<span class="n">personal_status_encoded</span></code></pre></div>
<pre><code>array([[0., 0., 0., 1.],
       [1., 0., 0., 0.],
       [0., 0., 0., 1.],
       ...,
       [0., 0., 0., 1.],
       [0., 0., 0., 1.],
       [0., 0., 0., 1.]])
</code></pre>
<p><code>sparse=False</code> se usa en <code>OneHotEncoder</code> a modo didáctico, para tener un visualización más fácil de los datos. Las matrices dispersas son estructuras eficientes de datos donde la mayoría de los elementos de la matriz son ceros.</p>
<p>Vemos que codificar una única columna nos dará una matriz NumPy repleta de ceros y unos. Lo comprenderemos mejor usando los nombres asociados de las features resultado de la transformación.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">feature_names</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(</span><span class="n">input_features</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;personal_status&#34;</span><span class="p">])</span>
<span class="n">personal_status_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">personal_status_encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">personal_status_encoded</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>personal_status_'female div/dep/mar'</th>
      <th>personal_status_'male div/sep'</th>
      <th>personal_status_'male mar/wid'</th>
      <th>personal_status_'male single'</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>997</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>999</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table></div>
<p>1000 rows × 4 columns</p>
</div>
<p>Como podemos ver, cada categoría se convierte en una columna; la codificación devolvió, para cada ejemplo, un 1 para especificar a qué categoría pertenece. Vamos a aplicarlo a todo el dataset.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_encoded</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>array([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1.],
       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1.],
       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 0., 1., 0., 0., 1.],
       [0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1.],
       [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1.]])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">columns_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns_encoded</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>checking_status_'0&lt;=X&lt;200'</th>
      <th>checking_status_'&lt;0'</th>
      <th>checking_status_'&gt;=200'</th>
      <th>checking_status_'no checking'</th>
      <th>credit_history_'all paid'</th>
      <th>credit_history_'critical/other existing credit'</th>
      <th>credit_history_'delayed previously'</th>
      <th>credit_history_'existing paid'</th>
      <th>credit_history_'no credits/all paid'</th>
      <th>purpose_'domestic appliance'</th>
      <th>...</th>
      <th>housing_own</th>
      <th>housing_rent</th>
      <th>job_'high qualif/self emp/mgmt'</th>
      <th>job_'unemp/unskilled non res'</th>
      <th>job_'unskilled resident'</th>
      <th>job_skilled</th>
      <th>own_telephone_none</th>
      <th>own_telephone_yes</th>
      <th>foreign_worker_no</th>
      <th>foreign_worker_yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table></div>
<p>5 rows × 54 columns</p>
</div>
<p>Echemos un vistazo a cómo la variable <code>purpose</code> ha sido codificada y comparémosla con su representación original. El número de features después del codificado es 10 veces mayor que su representación original, debido al elevado número de posibles categorías.</p>
<h3 id="eligiendo-una-estrategia-de-codificación"><a href="#eligiendo-una-estrategia-de-codificación" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Eligiendo una estrategia de codificación</h3>
<p>La elección de una estrategia de codificación dependerá de los modelos subyacentes y del tipo de categorías (es decir, ordinales vs nominales). En general, <code>OneHotEncoder</code> es la estrategia usada cuando los modelos posteriores son <strong>modelos lineales</strong> mientras que <code>OrdinalEncoder</code> es frecuentemente una buena estrategia con <strong>modelos basados en árboles</strong>.</p>
<p>Usar un <code>OrdinalEncoder</code> devolverá categorias ordinales. Esto significa que existe un orden en las categorías resultantes (es decir, <code>0 &lt; 1 &lt; 2</code>). El impacto de violar esta asunción de ordenación realmente depende de los modelos posteriores. Los modelos lineales se verán impactados por categorías desordenadas mientras que los modelos basados en árbol no.</p>
<p>Aun así podemos usar un <code>OrdinalEncoder</code> con modelos lineales pero necesitamos asegurarnos de que:</p>
<ul>
<li>las categorías originales (antes de codificar) tienen un orden;</li>
<li>las categorías codificadas siguen el mismo orden que las categorías originales.</li>
</ul>
<p>La codificación One-hot de variables categóricas con una alta cardinalidad pueden provocar ineficiencia computacional en modelos basados en árbol. Debido a esto, no es recomendable usar <code>OneHotEncoder</code> en tales casos, incluso aunque las categorías originales no tengan un orden dado.</p>
<h2 id="evaluar-nuestro-pipeline-predictivo"><a href="#evaluar-nuestro-pipeline-predictivo" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Evaluar nuestro pipeline predictivo</h2>
<p>Ahora podemos integrar este codificador dentro de un pipeline de machine learning como hicimos con los datos numéricos: entrenemos un clasificador lineal en los datos codificados y verifiquemos el rendimiento de generalización desde este pipeline de machine learning usando validación cruzada.</p>
<p>Antes de crear el pipeline veamos algunas situaciones que pueden ocurrir en la validación cruzada. Puede ocurrir que algunos valores de una variable categórica sucedan de forma muy infrecuente. Por ejemplo, con el ejemplo anterior de la variable <code>size</code> podemos tener que para la categoría <code>S</code> ocurra 24 veces, <code>M</code> ocurra 25 veces, <code>L</code> ocurra 21 veces y <code>XL</code> ocurra 1 vez. Esto puede ser un problema durante la validación cruzada: si la muestra termina en el conjunto de prueba durante la división, entonces el clasificador no vería esta categoría durante el entrenamiento y no sería capaz de codificarla. En scikit-learn, existen dos soluciones para solventar este problema:</p>
<ul>
<li>enumenar todos las posible categorías y proporcionarlas  al codificador a través del parámetro <code>categories</code>;</li>
<li>usar el parámetro <code>handle_unknown</code>.</li>
</ul>
<p>Por simplicidad, usaremos esta última solución.</p>
<p>Tengamos en cuenta que <code>OrdinalEncoder</code> también expone un parámetro <code>handle_unknown</code>. Puede ser establecido en <code>use_encoded_value</code> y estableciendo <code>unknown_value</code> para manejar categorías raras.</p>
<p>Ahora podemos crear nuestro pipeline de machine learning.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&#34;ignore&#34;</span><span class="p">),</span>
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="p">)</span></code></pre></div>
<p>Aquí necesitamos incrementar el número máximo de iteraciones para obtener una covergencia plena de <code>LogisticRegresion</code> y evitar un <code>ConvergenceWarning</code>. Al contrario que las features numéricas, las features categóricas codificadas one-hot tienen todas la misma escala (los valores son 0 o 1), por lo que no obtenemos ningún beneficio del escalado. En este caso, incrementar <code>max_iter</code> es la forma correcta de proceder.</p>
<p>Finalmente, vamos a comprobar el rendimiento de generalización del modelo usando únicamente las columnas categóricas.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">cv_results</span></code></pre></div>
<pre><code>{'fit_time': array([0.03252769, 0.02702308, 0.02702284, 0.02552271, 0.02652216]),
 'score_time': array([0.00300288, 0.00350356, 0.00300264, 0.00300264, 0.00300312]),
 'test_score': array([0.74 , 0.75 , 0.765, 0.72 , 0.73 ])}
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scores</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&#34;test_score&#34;</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;La precisión es: {scores.mean():.3f} +/- {scores.std():.3f}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>La precisión es: 0.741 +/- 0.016
</code></pre>
<p>En este caso, esta representación de las variables categóricas es ligeramente más predictiva del riesgo crediticio que las variables numéricas usadas anteriormente.</p>
<h1 id="usando-juntas-variables-numéricas-y-categóricas"><a href="#usando-juntas-variables-numéricas-y-categóricas" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Usando juntas variables numéricas y categóricas</h1>
<p>Hasta el momento hemos visto el preprocesamiento requerido cuando manejamos variables numéricas y categóricas. Sin embargo, desvinculamos el proceso para tratar cada tipo individualmente. Vamos a mostrar cómo combinar estos pasos de preprocesamiento.</p>
<h2 id="selección-basada-en-tipos-de-datos"><a href="#selección-basada-en-tipos-de-datos" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Selección basada en tipos de datos</h2>
<p>Repitamos de nuevo el procedimiento para separar las variables categóricas y numéricas según sus tipos de dato:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">target_name</span> <span class="o">=</span> <span class="s2">&#34;class&#34;</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">credit</span><span class="p">[</span><span class="n">target_name</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">credit</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_name</span><span class="p">])</span>

<span class="n">numerical_columns_selector</span> <span class="o">=</span> <span class="n">selector</span><span class="p">(</span><span class="n">dtype_exclude</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
<span class="n">categorical_columns_selector</span> <span class="o">=</span> <span class="n">selector</span><span class="p">(</span><span class="n">dtype_include</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

<span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">numerical_columns_selector</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">categorical_columns_selector</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code></pre></div>
<p>Atención, en este ejemplo sabemos que el tipo de datos <code>object</code> se usa para representar textos y, por tanto, features categóricas. Tengamos precaución porque esto no es siempre el caso. Algunas veces el tipo de dados <code>object</code> podría contener otros tipos de información, como fechas que no tenían el formato adecuado y, sin embargo, se relacionan a una cantidad de tiempo transcurrido.</p>
<p>En un escenario más general, deberíamos inspeccionar manualmente el contenido de nuestro dataframe para no usar equivocadamente <code>make_column_selector</code>.</p>
<h2 id="enviar-columnas-a-un-procesador-específico"><a href="#enviar-columnas-a-un-procesador-específico" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Enviar columnas a un procesador específico</h2>
<p>Ya vimos anteriormente que necesitamos tratar los datos de forma diferente dependiendo de su naturaleza (numérica o categórica). Scikit-learn proporciona una clase <code>ColumnTransformer</code> que enviará columnas específicas a transformadores específicos, haciendo fácil entrenar un único modelo predictivo en un dataset que combina ambos tipos de variables juntas (datos tabulares tipados heterogéneamente).</p>
<p>En primer lugar definimos las columnas dependiendo de su tipo de dato:</p>
<ul>
<li>La <strong>codificación one-hot</strong> se aplicará a las columnas categóricas. Además, usaremos <code>handle_unknown=&quot;ignore&quot;</code> para solventar el potencial problema debido a categorías raras.</li>
<li>El <strong>escalado numérico</strong> de las features numéricas será estandarizado.</li>
</ul>
<p>Ahora creamos nuestro <code>ColumnTransformer</code> especificando los tres valores: el nombre del preprocesador, el transformador y las columnas. En primer lugar, vamos a crear los preprocesadores para las partes numéricas y categóricas.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">categorical_preprocessor</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&#34;ignore&#34;</span><span class="p">)</span>
<span class="n">numerical_preprocessor</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span></code></pre></div>
<p>Ahora creamos el transformador y asociamos cada uno de los preprocesadores con sus respectivas columnas.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&#34;one-hot-encoder&#34;</span><span class="p">,</span> <span class="n">categorical_preprocessor</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&#34;standard_scaler&#34;</span><span class="p">,</span> <span class="n">numerical_preprocessor</span><span class="p">,</span> <span class="n">numerical_columns</span><span class="p">)</span>
<span class="p">])</span></code></pre></div>
<p>Vamos a representar gráficamente la estructura de <code>ColumnTransformer</code>:</p>
<p><img src="/images/column_transformer.png" alt=""></p>
<p>Un <code>ColumnTransformer</code> hace lo siguiente:</p>
<ul>
<li><strong>divide las columnas</strong> del dataset original basándose en los nombres de las columnas o índices proporcionados. Obtendremos tantos subconjuntos como números de transformadores pasados al <code>ColumnTransformer</code>.</li>
<li><strong>transforma cada subconjunto</strong>. Se aplica un transformador específico a cada subconjunto: internamente llamará a <code>fit_transform</code> o <code>transform</code>. La salida de este paso es un conjunto de datasets transformados.</li>
<li>por último, <strong>concatena los datasets transformados</strong> en un único dataset.</li>
</ul>
<p>Lo importante es que <code>ColumnTransformer</code> es como cualquier otro transformador de scikit-learn. Puede ser combinado con un clasificador en un <code>Pipeline</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s2">&#34;diagram&#34;</span><span class="p">)</span>
<span class="n">model</span></code></pre></div>
<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class="sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="4593f4e3-6ad6-4116-bb8c-35264e8bcd08" type="checkbox" ><label class="sk-toggleable__label" for="4593f4e3-6ad6-4116-bb8c-35264e8bcd08">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('columntransformer', ColumnTransformer(transformers=[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'),['checking_status','credit_history', 'purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing', 'own_telephone','foreign_worker']),('standard_scaler',StandardScaler(),['duration', 'credit_amount','installment_commitment','residence_since', 'age','existing_credits','num_dependents'])])),('logisticregression', LogisticRegression(max_iter=500))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="28b13a79-07ce-4ef7-bb21-70e5639f0d70" type="checkbox" ><label class="sk-toggleable__label" for="28b13a79-07ce-4ef7-bb21-70e5639f0d70">columntransformer: ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[('one-hot-encoder',OneHotEncoder(handle_unknown='ignore'),['checking_status', 'credit_history','purpose', 'employment','personal_status', 'other_parties','property_magnitude', 'other_payment_plans','housing', 'job', 'own_telephone','foreign_worker']),('standard_scaler', StandardScaler(),['duration', 'credit_amount','installment_commitment', 'residence_since','age', 'existing_credits','num_dependents'])])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="ac8c34c9-f6a7-4691-94de-9a0ea7a204ad" type="checkbox" ><label class="sk-toggleable__label" for="ac8c34c9-f6a7-4691-94de-9a0ea7a204ad">one-hot-encoder</label><div class="sk-toggleable__content"><pre>['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker']</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="f2ec9dd6-7b7f-4908-8c77-c46773019d1f" type="checkbox" ><label class="sk-toggleable__label" for="f2ec9dd6-7b7f-4908-8c77-c46773019d1f">OneHotEncoder</label><div class="sk-toggleable__content"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="bfbe5363-1d03-4406-a5f7-fad8ed53b97f" type="checkbox" ><label class="sk-toggleable__label" for="bfbe5363-1d03-4406-a5f7-fad8ed53b97f">standard_scaler</label><div class="sk-toggleable__content"><pre>['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="30d7d67f-3d6e-4933-bf7e-0022b086c45d" type="checkbox" ><label class="sk-toggleable__label" for="30d7d67f-3d6e-4933-bf7e-0022b086c45d">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="c5b127e3-cbaa-4fdc-8a1f-bed669fd64c2" type="checkbox" ><label class="sk-toggleable__label" for="c5b127e3-cbaa-4fdc-8a1f-bed669fd64c2">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div></div></div>
<p>El modelo final es más complejo que los que hemos visto previamente pero aún sigue la misma API (el mismo conjunto de métodos que pueden ser llamados por el usuario):</p>
<ul>
<li>el metodo <code>fit</code> es llamado para preprocesar los datos y luego entrenar el clasificador en los datos preprocesados;</li>
<li>el metodo <code>predict</code> hace predicciones en datos nuevos;</li>
<li>el metodo <code>score</code> es usado para predecir en los datos de prueba y comparar las predicciones con las etiquetas de prueba esperadas para calcular la precisión.</li>
</ul>
<p>Empecemos dividiendo nuestros datos en los conjuntos de entrenamiento y prueba:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code></pre></div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></div>
<p>Luego, podemos enviar el dataset en bruto directamente al pipeline. De hecho, no necesitamos hacer ningún preprocesamiento manual (llamando a los métodos <code>transform</code> o <code>fit_transform</code>) ya que será manejado cuando llamemos al método <code>predict</code>. Como ejemplo, predeciremos en los primeros cinco ejemplos del conjunto de prueba.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<div class="table-container"><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>checking_status</th>
      <th>duration</th>
      <th>credit_history</th>
      <th>purpose</th>
      <th>credit_amount</th>
      <th>savings_status</th>
      <th>employment</th>
      <th>installment_commitment</th>
      <th>personal_status</th>
      <th>other_parties</th>
      <th>residence_since</th>
      <th>property_magnitude</th>
      <th>age</th>
      <th>other_payment_plans</th>
      <th>housing</th>
      <th>existing_credits</th>
      <th>job</th>
      <th>num_dependents</th>
      <th>own_telephone</th>
      <th>foreign_worker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>521</th>
      <td>'&lt;0'</td>
      <td>18</td>
      <td>'existing paid'</td>
      <td>radio/tv</td>
      <td>3190</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>2</td>
      <td>'female div/dep/mar'</td>
      <td>none</td>
      <td>2</td>
      <td>'real estate'</td>
      <td>24</td>
      <td>none</td>
      <td>own</td>
      <td>1</td>
      <td>skilled</td>
      <td>1</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>737</th>
      <td>'&lt;0'</td>
      <td>18</td>
      <td>'existing paid'</td>
      <td>'new car'</td>
      <td>4380</td>
      <td>'100&lt;=X&lt;500'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>3</td>
      <td>'male single'</td>
      <td>none</td>
      <td>4</td>
      <td>car</td>
      <td>35</td>
      <td>none</td>
      <td>own</td>
      <td>1</td>
      <td>'unskilled resident'</td>
      <td>2</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>740</th>
      <td>'&lt;0'</td>
      <td>24</td>
      <td>'all paid'</td>
      <td>'new car'</td>
      <td>2325</td>
      <td>'100&lt;=X&lt;500'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>2</td>
      <td>'male single'</td>
      <td>none</td>
      <td>3</td>
      <td>car</td>
      <td>32</td>
      <td>bank</td>
      <td>own</td>
      <td>1</td>
      <td>skilled</td>
      <td>1</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>660</th>
      <td>'&gt;=200'</td>
      <td>12</td>
      <td>'existing paid'</td>
      <td>radio/tv</td>
      <td>1297</td>
      <td>'&lt;100'</td>
      <td>'1&lt;=X&lt;4'</td>
      <td>3</td>
      <td>'male mar/wid'</td>
      <td>none</td>
      <td>4</td>
      <td>'real estate'</td>
      <td>23</td>
      <td>none</td>
      <td>rent</td>
      <td>1</td>
      <td>skilled</td>
      <td>1</td>
      <td>none</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>411</th>
      <td>'no checking'</td>
      <td>33</td>
      <td>'critical/other existing credit'</td>
      <td>'used car'</td>
      <td>7253</td>
      <td>'&lt;100'</td>
      <td>'4&lt;=X&lt;7'</td>
      <td>3</td>
      <td>'male single'</td>
      <td>none</td>
      <td>2</td>
      <td>car</td>
      <td>35</td>
      <td>none</td>
      <td>own</td>
      <td>2</td>
      <td>'high qualif/self emp/mgmt'</td>
      <td>1</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>array(['good', 'bad', 'bad', 'good', 'good'], dtype=object)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<pre><code>521     bad
737    good
740    good
660    good
411    good
Name: class, dtype: object
</code></pre>
<p>Para obtener directamente la puntuación de precisión, necesitamos llamar al método <code>score</code>. Calculemos la puntuación de precisión del conjunto de pruebas completo.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></code></pre></div>
<pre><code>0.768
</code></pre>
<h2 id="evaluación-del-modelo-con-validación-cruzada"><a href="#evaluación-del-modelo-con-validación-cruzada" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Evaluación del modelo con validación cruzada</h2>
<p>Como vimos anteriormente, un modelo predictivo debe ser evaluado con validación cruzada. Nuestro modelo es utilizable con herramientas de validación cruzada de scikit-learn como cualquier otro predictor:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv_results</span></code></pre></div>
<pre><code>{'fit_time': array([0.04668927, 0.04341388, 0.04553866, 0.04053569, 0.03930879]),
 'score_time': array([0.00600529, 0.00600529, 0.006495  , 0.00568366, 0.00550437]),
 'test_score': array([0.75, 0.76, 0.76, 0.74, 0.75])}
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scores</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&#34;test_score&#34;</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;La precisión media por validación cruzada es: &#34;</span>
      <span class="n">f</span><span class="s2">&#34;{scores.mean():.3f} +/- {scores.std():.3f}&#34;</span><span class="p">)</span></code></pre></div>
<pre><code>La precisión media por validación cruzada es: 0.752 +/- 0.007
</code></pre>
<p>El modelo compuesto tiene una mayor precisión predicitiva que los dos modelos que utilizan variables numéricas y categóricas por separado.</p>
<h1 id="resumen"><a href="#resumen" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Resumen</h1>
<p>A modo de resumen hemos visto:</p>
<ul>
<li>cómo crear un modelo predictivo con scikit-learn;</li>
<li>la API de scikit-learn para entrenar y probar un modelo predictivo;</li>
<li>procesar datos numéricos, en particular usando un <code>Pipeline</code>;</li>
<li>procesar datos categóricos, en particular usando <code>OneHotEncoder</code> y <code>OrdinalEncoder</code>;</li>
<li>manejar y procesar tipos de datos mixtos (es decir, datos numéricos y categóricos), en particular usando <code>ColumnTransformer</code>.</li>
</ul>
<p>Algunas referencias a seguir con ejemplos de algunos conceptos mencionados:</p>
<ul>
<li><a href="https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py" target="_blank" rel="noopener">Pipeline predictivo de machine learning con tipos de datos mixtos</a>.</li>
<li><a href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py" target="_blank" rel="noopener">Importancia del escalado de features</a>.</li>
</ul>

            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text"></span><a href="https://sgtsteiner.github.io/" class="p-author h-card" target="_blank" rel="noopener">Antonio Méndez</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text"></span><a href="/posts/predictive-modeling-pipeline/" target="_blank" rel="noopener">https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text"></span><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></li>
            
        </ul>
    



        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2022-03-22 19:35:25 CET" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2022-03-22</text><text x="915" y="140" textLength="650" transform="scale(.1)">2022-03-22</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/&amp;text=Pipeline%20de%20modelado%20predictivo&amp;hashtags=pipeline,regresi%c3%b3nlog%c3%adstica,validaci%c3%b3ncruzada,baseline,one-hotencoding,ordinalencoding,ColumnTransformer,escalado,&amp;via=Steiner_69" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/&amp;title=Pipeline%20de%20modelado%20predictivo&amp;summary=En%20este%20post%20vamos%20a%20presentar%20un%20ejemplo%20de%20un%20pipeline%20de%20modelado%20predictivo%20t%c3%adpico%20usando%20datos%20tabulares,%20es%20decir,%20que%20pueden%20ser%20estructurados%20en%20una%20tabla%20de%202%20dimensiones.%20En%20primer%20lugar,%20analizaremos%20el%20dataset%20usado%20y%20posteriormente%20entrenaremos%20un%20primer%20pipeline%20predictivo.&amp;source=Lords%20of%20the%20Machine%20Learning" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://sgtsteiner.github.io/posts/predictive-modeling-pipeline/&amp;text=Pipeline%20de%20modelado%20predictivo" title="" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            

            

            

            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/sgtsteiner.github.io\/posts\/predictive-modeling-pipeline\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    
        <div class="related-posts">
            <h2 class="related-title"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg></h2>
            <ul class="related-list">
                
                    <li class="related-item">
                        <a href="/posts/selecting-best-model/" class="related-link">Selección del mejor modelo</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/posts/hyperparameters-tuning/" class="related-link">Ajuste de hiperparámetros</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/posts/30daysofml/" class="related-link">30 Days of ML</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/posts/wine-quality-clasificacion-multiclase/" class="related-link">Calidad del vino - Clasificación multiclase</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/posts/wine-quality-un-problema-de-regresion/" class="related-link">Calidad del vino - Un problema de regresión</a>
                    </li>
                
            </ul>
        </div>
    



        
    
        <div class="post-tags">
            
                
                
                
                
                    
                    <a href="/tags/pipeline/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>pipeline</a>
                
            
                
                
                
                
                    
                    <a href="/tags/regresi%C3%B3n-log%C3%ADstica/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>regresión logística</a>
                
            
                
                
                
                
                    
                    <a href="/tags/validaci%C3%B3n-cruzada/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>validación cruzada</a>
                
            
                
                
                
                
                    
                    <a href="/tags/baseline/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>baseline</a>
                
            
                
                
                
                
                    
                    <a href="/tags/one-hot-encoding/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>one-hot encoding</a>
                
            
                
                
                
                
                    
                    <a href="/tags/ordinal-encoding/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>ordinal encoding</a>
                
            
                
                
                
                
                    
                    <a href="/tags/columntransformer/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>ColumnTransformer</a>
                
            
                
                
                
                
                    
                    <a href="/tags/escalado/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>escalado</a>
                
            
        </div>
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
                <li class="post-nav-prev">
                    <a href="/posts/selecting-best-model/" rel="prev">&lt; Selección del mejor modelo</a>
                </li>
            
            
                <li class="post-nav-next">
                    <a href="/posts/30daysofml/" rel="next">30 Days of ML &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;2021–2022&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;Antonio Méndez</div><div class="site-copyright"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="/rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="mailto:futitotal@gmail.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/SgtSteiner" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/Steiner_69" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://t.me/SgtSteiner" target="_blank" rel="external noopener" title="Telegram"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    mediumZoom(document.querySelectorAll('div.post-body img'), {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>







    </body>
</html>
