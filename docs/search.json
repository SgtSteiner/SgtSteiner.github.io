[{"categories":null,"content":"En este post repasaremos las principales fases que componen un proyecto de Machine Learning.\nExisten ocho pasos principales:\n  Encuadrar el problema y disponer de la visión global.\n  Obtener los datos.\n  Explorar los datos para obtener ideas.\n  Preparar los datos para exponer lo mejor posible los patrones de datos subyacentes a los algoritmos de Machine Learning.\n  Explorar muchos modelos diferentes y preseleccionar los mejores.\n  Afinar nuestros modelos y combinarlos en una gran solución.\n  Presentar nuestra solución.\n  Implantar, monitorizar y mantener nuestro sistema.\n  Disponemos un conjunto de datos que contiene diversas características de variantes de tinto y blanco del vino portugués “Vinho Verde”. Disponemos de variables químicas, como son la cantidad de alcohol, ácido cítrico, acidez, densidad, pH, etc; así como de una variable sensorial y subjetiva como es la puntuación con la que un grupo de expertos calificaron la calidad del vino: entre 0 (muy malo) y 10 (muy excelente).\nEl objetivo es desarrollar un modelo que pueda predecir la puntuación de calidad dados dichos indicadores bioquímicos.\nLo primero que nos viene a la mente son una serie de preguntas básicas:\n  ¿Cómo se enmarcaría este problema (supervisado, no supervisado, etc.)?\n  ¿Cuál es la variable objetivo? ¿Cuáles son los predictores?\n  ¿Cómo vamos a medir el rendimiento de nuestro modelo?\n  El codigo python utilizado en este artículo está disponible en mi repositorio github\nEn primer lugar importamos todas las librerías necesarias:\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, ElasticNet, Ridge from sklearn.dummy import DummyRegressor from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor from sklearn.svm import SVR from sklearn import metrics %matplotlib inline Get the Data red = pd.read_csv(\"data/wine-quality/winequality-red.csv\") Check the size and type of data red.shape (1599, 12)  red.head()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality     0 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5   1 7.8 0.88 0.00 2.6 0.098 25.0 67.0 0.9968 3.20 0.68 9.8 5   2 7.8 0.76 0.04 2.3 0.092 15.0 54.0 0.9970 3.26 0.65 9.8 5   3 11.2 0.28 0.56 1.9 0.075 17.0 60.0 0.9980 3.16 0.58 9.8 6   4 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5     red.info() \u003cclass 'pandas.core.frame.DataFrame'\u003e RangeIndex: 1599 entries, 0 to 1598 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 fixed acidity 1599 non-null float64 1 volatile acidity 1599 non-null float64 2 citric acid 1599 non-null float64 3 residual sugar 1599 non-null float64 4 chlorides 1599 non-null float64 5 free sulfur dioxide 1599 non-null float64 6 total sulfur dioxide 1599 non-null float64 7 density 1599 non-null float64 8 pH 1599 non-null float64 9 sulphates 1599 non-null float64 10 alcohol 1599 non-null float64 11 quality 1599 non-null int64 dtypes: float64(11), int64(1) memory usage: 150.0 KB  pd.DataFrame({\"Type\": red.dtypes, \"Unique\": red.nunique(), \"Null\": red.isnull().sum(), \"Null percent\": red.isnull().sum() / len(red), \"Mean\": red.mean(), \"Std\": red.std()})  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Type Unique Null Null percent Mean Std     fixed acidity float64 96 0 0.0 8.319637 1.741096   volatile acidity float64 143 0 0.0 0.527821 0.179060   citric acid float64 80 0 0.0 0.270976 0.194801   residual sugar float64 91 0 0.0 2.538806 1.409928   chlorides float64 153 0 0.0 0.087467 0.047065   free sulfur dioxide float64 60 0 0.0 15.874922 10.460157   total sulfur dioxide float64 144 0 0.0 46.467792 32.895324   density float64 436 0 0.0 0.996747 0.001887   pH float64 89 0 0.0 3.311113 0.154386   sulphates float64 96 0 0.0 0.658149 0.169507   alcohol float64 65 0 0.0 10.422983 1.065668   quality int64 6 0 0.0 5.636023 0.807569     Mmmmm, there are no nulls, what a data set!\nred.describe().T  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  count mean std min 25% 50% 75% max     fixed acidity 1599.0 8.319637 1.741096 4.60000 7.1000 7.90000 9.200000 15.90000   volatile acidity 1599.0 0.527821 0.179060 0.12000 0.3900 0.52000 0.640000 1.58000   citric acid 1599.0 0.270976 0.194801 0.00000 0.0900 0.26000 0.420000 1.00000   residual sugar 1599.0 2.538806 1.409928 0.90000 1.9000 2.20000 2.600000 15.50000   chlorides 1599.0 0.087467 0.047065 0.01200 0.0700 0.07900 0.090000 0.61100   free sulfur dioxide 1599.0 15.874922 10.460157 1.00000 7.0000 14.00000 21.000000 72.00000   total sulfur dioxide 1599.0 46.467792 32.895324 6.00000 22.0000 38.00000 62.000000 289.00000   density 1599.0 0.996747 0.001887 0.99007 0.9956 0.99675 0.997835 1.00369   pH 1599.0 3.311113 0.154386 2.74000 3.2100 3.31000 3.400000 4.01000   sulphates 1599.0 0.658149 0.169507 0.33000 0.5500 0.62000 0.730000 2.00000   alcohol 1599.0 10.422983 1.065668 8.40000 9.5000 10.20000 11.100000 14.90000   quality 1599.0 5.636023 0.807569 3.00000 5.0000 6.00000 6.000000 8.00000     Explore the Data How are the features distributed?\nred.hist(bins=50, figsize=(15,12)); Let’s check how our target variable, the quality score, is distributed:\nprint(f\"Percentage of quality scores\") red[\"quality\"].value_counts(normalize=True) * 100 Percentage of quality scores 5 42.589118 6 39.899937 7 12.445278 4 3.314572 8 1.125704 3 0.625391 Name: quality, dtype: float64  It is significantly unbalanced. Most instances (82%) have scores of 6 or 5.\nWe are going to check the correlations between the attributes of the dataset:\ncorr_matrix = red.corr() corr_matrix  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality     fixed acidity 1.000000 -0.256131 0.671703 0.114777 0.093705 -0.153794 -0.113181 0.668047 -0.682978 0.183006 -0.061668 0.124052   volatile acidity -0.256131 1.000000 -0.552496 0.001918 0.061298 -0.010504 0.076470 0.022026 0.234937 -0.260987 -0.202288 -0.390558   citric acid 0.671703 -0.552496 1.000000 0.143577 0.203823 -0.060978 0.035533 0.364947 -0.541904 0.312770 0.109903 0.226373   residual sugar 0.114777 0.001918 0.143577 1.000000 0.055610 0.187049 0.203028 0.355283 -0.085652 0.005527 0.042075 0.013732   chlorides 0.093705 0.061298 0.203823 0.055610 1.000000 0.005562 0.047400 0.200632 -0.265026 0.371260 -0.221141 -0.128907   free sulfur dioxide -0.153794 -0.010504 -0.060978 0.187049 0.005562 1.000000 0.667666 -0.021946 0.070377 0.051658 -0.069408 -0.050656   total sulfur dioxide -0.113181 0.076470 0.035533 0.203028 0.047400 0.667666 1.000000 0.071269 -0.066495 0.042947 -0.205654 -0.185100   density 0.668047 0.022026 0.364947 0.355283 0.200632 -0.021946 0.071269 1.000000 -0.341699 0.148506 -0.496180 -0.174919   pH -0.682978 0.234937 -0.541904 -0.085652 -0.265026 0.070377 -0.066495 -0.341699 1.000000 -0.196648 0.205633 -0.057731   sulphates 0.183006 -0.260987 0.312770 0.005527 0.371260 0.051658 0.042947 0.148506 -0.196648 1.000000 0.093595 0.251397   alcohol -0.061668 -0.202288 0.109903 0.042075 -0.221141 -0.069408 -0.205654 -0.496180 0.205633 0.093595 1.000000 0.476166   quality 0.124052 -0.390558 0.226373 0.013732 -0.128907 -0.050656 -0.185100 -0.174919 -0.057731 0.251397 0.476166 1.000000     plt.figure(figsize=(15,10)) sns.heatmap(red.corr(), annot=True, cmap='coolwarm') plt.show() We show only the correlations of the target variable with the rest of the attributes:\ncorr_matrix[\"quality\"].drop(\"quality\").sort_values(ascending=False) alcohol 0.476166 sulphates 0.251397 citric acid 0.226373 fixed acidity 0.124052 residual sugar 0.013732 free sulfur dioxide -0.050656 pH -0.057731 chlorides -0.128907 density -0.174919 total sulfur dioxide -0.185100 volatile acidity -0.390558 Name: quality, dtype: float64  plt.figure(figsize=(8,5)) corr_matrix[\"quality\"].drop(\"quality\").sort_values(ascending=False).plot(kind='bar') plt.title(\"Attribute correlations with quality\") plt.show() Prepare the Data Create the predictor set and the set with the target variable:\npredict_columns = red.columns[:-1] predict_columns Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'], dtype='object')  X = red[predict_columns] y = red[\"quality\"] Create the training and test datasets:\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2) X_train.shape, y_train.shape ((1279, 11), (1279,))  X_test.shape, y_test.shape ((320, 11), (320,))  Baseline def evaluate_model(estimator, X_train, y_train, cv=10, verbose=True): \"\"\"Print and return cross validation of model \"\"\" scoring = [\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"r2\"] scores = cross_validate(estimator, X_train, y_train, return_train_score=True, cv=cv, scoring=scoring) val_mae_mean, val_mae_std = -scores['test_neg_mean_absolute_error'].mean(), \\ -scores['test_neg_mean_absolute_error'].std() train_mae_mean, train_mae_std = -scores['train_neg_mean_absolute_error'].mean(), \\ -scores['train_neg_mean_absolute_error'].std() val_mse_mean, val_mse_std = -scores['test_neg_mean_squared_error'].mean(), \\ -scores['test_neg_mean_squared_error'].std() train_mse_mean, train_mse_std = -scores['train_neg_mean_squared_error'].mean(), \\ -scores['train_neg_mean_squared_error'].std() val_rmse_mean, val_rmse_std = np.sqrt(-scores['test_neg_mean_squared_error']).mean(), \\ np.sqrt(-scores['test_neg_mean_squared_error']).std() train_rmse_mean, train_rmse_std = np.sqrt(-scores['train_neg_mean_squared_error']).mean(), \\ np.sqrt(-scores['train_neg_mean_squared_error']).std() val_r2_mean, val_r2_std = scores['test_r2'].mean(), scores['test_r2'].std() train_r2_mean, train_r2_std = scores['train_r2'].mean(), scores['train_r2'].std() result = { \"Val MAE\": val_mae_mean, \"Val MAE std\": val_mae_std, \"Train MAE\": train_mae_mean, \"Train MAE std\": train_mae_std, \"Val MSE\": val_mse_mean, \"Val MSE std\": val_mse_std, \"Train MSE\": train_mse_mean, \"Train MSE std\": train_mse_std, \"Val RMSE\": val_rmse_mean, \"Val RMSE std\": val_rmse_std, \"Train RMSE\": train_rmse_mean, \"Train RMSE std\": train_rmse_std, \"Val R2\": val_r2_mean, \"Val R2 std\": val_r2_std, \"Train R2\": train_rmse_mean, \"Train R2 std\": train_r2_std, } if verbose: print(f\"val_MAE_mean: {val_mae_mean} - (std: {val_mae_std})\") print(f\"train_MAE_mean: {train_mae_mean} - (std: {train_mae_std})\") print(f\"val_MSE_mean: {val_mse_mean} - (std: {val_mse_std})\") print(f\"train_MSE_mean: {train_mse_mean} - (std: {train_mse_std})\") print(f\"val_RMSE_mean: {val_rmse_mean} - (std: {val_rmse_std})\") print(f\"train_RMSE_mean: {train_rmse_mean} - (std: {train_rmse_std})\") print(f\"val_R2_mean: {val_r2_mean} - (std: {val_r2_std})\") print(f\"train_R2_mean: {train_r2_mean} - (std: {train_r2_std})\") return result First, we are going to train a dummy regressor that we will use as a baseline with which to compare.\nrg_dummy = DummyRegressor(strategy=\"constant\", constant=5) # Mean prediction rg_dummy.fit(X_train, y_train) DummyRegressor(constant=array(5), strategy='constant')  rg_scores = evaluate_model(rg_dummy, X_train, y_train) val_MAE_mean: 0.719365157480315 - (std: -0.06352462970037416) train_MAE_mean: 0.7193126146346173 - (std: -0.007057414168822716) val_MSE_mean: 1.0398868110236221 - (std: -0.12176257291946108) train_MSE_mean: 1.0398750482672072 - (std: -0.01354074583910719) val_RMSE_mean: 1.0180017820772593 - (std: 0.05965888627141756) train_RMSE_mean: 1.0197209977802941 - (std: 0.006643414270421584) val_R2_mean: -0.6192850555554466 - (std: 0.14799333040101653) train_R2_mean: -0.5986022943608599 - (std: 0.01598456942915052)  A classifier that always predicts the most frequent quality (in our case the quality score 5) obtains a RMSE = 1.039.\nrg_dummy = DummyRegressor(strategy=\"mean\") # Mean prediction rg_dummy.fit(X_train, y_train) DummyRegressor()  rg_scores = evaluate_model(rg_dummy, X_train, y_train) val_MAE_mean: 0.6842639509806605 - (std: -0.039939453843720794) train_MAE_mean: 0.6836374055181736 - (std: -0.004461928774514038) val_MSE_mean: 0.6515564887161005 - (std: -0.08938937463665708) train_MSE_mean: 0.6505431870574859 - (std: -0.009928873673332832) val_RMSE_mean: 0.8052590895459458 - (std: 0.05580580095057208) train_RMSE_mean: 0.8065390950374436 - (std: 0.006154285796714715) val_R2_mean: -0.007632943779434287 - (std: 0.010684535533448955) train_R2_mean: 0.0 - (std: 0.0)  A regressor that always predicts the mean quality obtains a RMSE = 0.651. We are going to take the prediction of this dummy classifier as our baseline.\nShortlist Promising Models OK, we’re going train several quick-and-dirty models from different categories using standard parameters. We selected some of the regression models: Linear Regression, Lasso, ElasticNet, Ridge, Extre Trees, and RandomForest.\nmodels = [LinearRegression(), Lasso(alpha=0.1), ElasticNet(), Ridge(), ExtraTreesRegressor(), RandomForestRegressor()] model_names = [\"Lineal Regression\", \"Lasso\", \"ElasticNet\", \"Ridge\", \"Extra Tree\", \"Random Forest\"] mae = [] mse = [] rmse = [] r2 = [] for model in range(len(models)): print(f\"Paso {model+1} de {len(models)}\") print(f\"...running {model_names[model]}\") rg_scores = evaluate_model(models[model], X_train, y_train) mae.append(rg_scores[\"Val MAE\"]) mse.append(rg_scores[\"Val MSE\"]) rmse.append(rg_scores[\"Val RMSE\"]) r2.append(rg_scores[\"Val R2\"]) Paso 1 de 6 ...running Lineal Regression val_MAE_mean: 0.5054157041773433 - (std: -0.046264972549372924) train_MAE_mean: 0.49951141240221786 - (std: -0.005396834677886112) val_MSE_mean: 0.4363366846653876 - (std: -0.0713599197838867) train_MSE_mean: 0.423559916011364 - (std: -0.007783364048942027) val_RMSE_mean: 0.6578988186927084 - (std: 0.059210041615646476) train_RMSE_mean: 0.6507877560250832 - (std: 0.005934022177307515) val_R2_mean: 0.32302131635332426 - (std: 0.0972958323285871) train_R2_mean: 0.34888336017832816 - (std: 0.008988207786517072) Paso 2 de 6 ...running Lasso val_MAE_mean: 0.5542159398138832 - (std: -0.044044881537899525) train_MAE_mean: 0.551926769360105 - (std: -0.005222359881914205) val_MSE_mean: 0.5011613158962728 - (std: -0.07980261731926688) train_MSE_mean: 0.49648903729654775 - (std: -0.00886434349442919) val_RMSE_mean: 0.7054560563903938 - (std: 0.05910218607112876) train_RMSE_mean: 0.7045920060170998 - (std: 0.006256385006291075) val_R2_mean: 0.22550457016915199 - (std: 0.06858817248045986) train_R2_mean: 0.23679715721911138 - (std: 0.008061051196907644) Paso 3 de 6 ...running ElasticNet val_MAE_mean: 0.6484828644185054 - (std: -0.03858618665902155) train_MAE_mean: 0.6472074434172257 - (std: -0.004861676284701619) val_MSE_mean: 0.6260699925252777 - (std: -0.08837053843631361) train_MSE_mean: 0.6236958050351286 - (std: -0.009753039023728842) val_RMSE_mean: 0.7891968495348196 - (std: 0.056906284447264595) train_RMSE_mean: 0.7897200517246066 - (std: 0.0061680579774354895) val_R2_mean: 0.032300440343033296 - (std: 0.027013749786509673) train_R2_mean: 0.041268269123349036 - (std: 0.0034334107542665303) Paso 4 de 6 ...running Ridge val_MAE_mean: 0.5052017417711606 - (std: -0.04639189777979148) train_MAE_mean: 0.5000120146851917 - (std: -0.00538293390792397) val_MSE_mean: 0.4353611411950837 - (std: -0.07150445371257734) train_MSE_mean: 0.4243933932521361 - (std: -0.007774091981744382) val_RMSE_mean: 0.6571341500690723 - (std: 0.05946301378236467) train_RMSE_mean: 0.6514279204128516 - (std: 0.0059209592739344254) val_R2_mean: 0.32476443307512515 - (std: 0.09605257129964452) train_R2_mean: 0.3476024511130947 - (std: 0.0089301257345918) Paso 5 de 6 ...running Extra Tree val_MAE_mean: 0.3767233021653543 - (std: -0.048411131876621855) train_MAE_mean: -0.0 - (std: -0.0) val_MSE_mean: 0.33849758981299216 - (std: -0.07037684927470149) train_MSE_mean: -0.0 - (std: -0.0) val_RMSE_mean: 0.5784725891678845 - (std: 0.062185636560190514) train_RMSE_mean: 0.0 - (std: 0.0) val_R2_mean: 0.4753582472917177 - (std: 0.09435328966382882) train_R2_mean: 1.0 - (std: 0.0) Paso 6 de 6 ...running Random Forest val_MAE_mean: 0.421939406988189 - (std: -0.03848180259232641) train_MAE_mean: 0.15720688154624 - (std: -0.0024955091475250693) val_MSE_mean: 0.3536394728100393 - (std: -0.06315688035394738) train_MSE_mean: 0.049982221460505356 - (std: -0.0012897300801719821) val_RMSE_mean: 0.5921558699969636 - (std: 0.05468910712544724) train_RMSE_mean: 0.22354850027354933 - (std: 0.0028791467403151403) val_R2_mean: 0.450229047801475 - (std: 0.08970981370698214) train_R2_mean: 0.9231573754360927 - (std: 0.0020715859571618753)  Let’s see the performance of each of them:\ndf_result = pd.DataFrame({\"Model\": model_names, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}) df_result  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Model MAE MSE RMSE R2     0 Lineal Regression 0.505416 0.436337 0.657899 0.323021   1 Lasso 0.554216 0.501161 0.705456 0.225505   2 ElasticNet 0.648483 0.626070 0.789197 0.032300   3 Ridge 0.505202 0.435361 0.657134 0.324764   4 Extra Tree 0.376723 0.338498 0.578473 0.475358   5 Random Forest 0.421939 0.353639 0.592156 0.450229     df_result.sort_values(by=\"RMSE\", ascending=False).plot.barh(\"Model\", \"RMSE\"); df_result.sort_values(by=\"R2\").plot.barh(\"Model\", \"R2\"); The model that gives the best results is extra trees. RMSE = 0.577591 and R2 = 0.477845. Let’s fine tune it.\nFine-Tune param_grid = [ {'n_estimators': range(10, 300, 10), 'max_features': [2, 3, 4, 5, 8, \"auto\"], 'bootstrap': [True, False]} ] xtree_reg = ExtraTreesRegressor(random_state=42, n_jobs=-1) grid_search = GridSearchCV(xtree_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True) grid_search.fit(X_train, y_train) grid_search.best_params_ It’s the moment of truth! Let’s see the performance on the test set:\nfinal_model = grid_search.best_estimator_ y_pred = final_model.predict(X_test) print(f\"MAE: {metrics.mean_absolute_error(y_test, y_pred)}\") print(f\"MSE: {metrics.mean_squared_error(y_test, y_pred)}\") print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}\") print(f\"R2: {final_model.score(X_test, y_test)}\") Well, a little better!\nplt.figure(figsize=(10,8)) plt.scatter(y_test, y_pred, alpha=0.1) plt.xlabel(\"Real\") plt.ylabel(\"Predicted\") plt.show() Let’s see which features are most relevant:\nfeature_importances = final_model.feature_importances_ feature_importances sorted(zip(feature_importances, X_test.columns), reverse=True) feature_imp = pd.Series(feature_importances, index=X_train.columns).sort_values(ascending=False) feature_imp.plot(kind='bar') plt.title('Feature Importances') Let’s see how the errors are distributed:\ndf_resul = pd.DataFrame({\"Pred\": y_pred, \"Real\": y_test, \"error\": y_pred - y_test, \"error_abs\": abs(y_pred - y_test)}) df_resul[\"error\"].plot.hist(bins=40, density=True) plt.title(\"Error distribution\") plt.xlabel(\"Error\"); More generally, What’s the MAE that occurs in each quality score?\ndf_resul.groupby(\"Real\")[\"error_abs\"].mean() df_resul.groupby(\"Real\")[\"error_abs\"].mean().plot.bar() plt.title(\"MAE distribution\") plt.ylabel(\"MAE\") plt.xlabel(\"Quality\"); Conclusions After testing various models, the one that provided the best results is ExtraTrees. After fine tuning it, we get a significant improvement.\nThe basic line regression model offers an R2: 0.323021 and RMSE: 0.657899. The Extra Tree model offers an R2: 0.529512 and RMSE: 0.570954. However, the R2 score is still very low. According to the value obtained from R2, our model can barely explain 52% of the variance. That is, the percentage of relationship between the variables that can be explained by our model is 52.95%.\nAccording to the MAE distribution graph, we can see that our model is not good for extreme scores. In fact, it is not capable of predicting any score of 3 or 8. As we saw in the distribution of the target variable, it is very unbalanced, there are hardly any observations for the extreme values, so the model does not have enough data training for all quality scores.\nAs a final consideration, we should try to approach modeling as a classification problem, to evaluate if it offers better results than a regression problem. We will see it in part 2 and 3 of this analysis.\n","description":"","tags":null,"title":"Calidad del vino - Un problema de regresión","uri":"/posts/wine-quality-un-problema-de-regresion/"},{"categories":["taxonomía"],"content":"Lee Sedol tenía solo 12 años cuando se convirtió en uno de los jugadores profesionales de Go más jóvenes de la historia. Cuando el 9 de marzo de 2016 cruzó las puertas del Hotel Four Seasons de Seúl tenía 33 años y era 18 veces campeón del mundo. Le esperaban cinco intensas partidas contra un duro contrincante. Ante el asombro general perdió 4-1. Ese día pasaría a la historia como el día en que el campeón del mundo de Go perdió contra AlphaGo, un programa informático perteneciente a la división DeepMind de Google. Lee Sedol también pasaría a la historia como el único humano que ha ganado una partida a AlphaGo (aunque posteriormente reconocería que fue debido a un error en su programa).\nGran parte de la magia negra de AlphaGo proviene del uso de técnicas y sistemas de Machine Learning e Inteligencia Artificial. Los sistemas de Machine learning (ML) o aprendizaje automático, están detrás de muchos de los productos de alta tecnología que nos rodean, de los motores de búsqueda de webs, del reconocimiento de habla de nuestros dispositivos, nos recomienda películas y series en nuestras plataformas de streaming favoritas, detecta el spam de nuestros correos, etc.\nPero ¿qué es machine Learning y qué significa que una máquina pueda aprender algo? Según la definición académica de Arthur Samuel, que popularizó dicho término en 1959, machine Learning es el campo de estudio que proporciona a los ordenadores la habilidad de aprender sin ser explícitamente programados. Como informáticos que somos, aquí va otra definición más “ingenieril”: Un programa de ordenador se dice que aprende de una experiencia E con respecto a alguna tarea T y alguna medida de la ejecución P, si su ejecución en T, medida por P, mejora con la experiencia E. (Tom Mitchell, 1997)\nEn vista de esto ¿si nos descargamos una copia de Wikipedia o la Hemeroteca Digital, nuestros ordenadores están aprendiendo algo? Evidentemente no. Dispondremos de una cantidad enorme de datos, pero de repente nuestras máquinas no serán mejores en ninguna tarea.\n¿Qué ventajas ofrece el uso de machine learning sobre otras técnicas de programación tradicionales? Utilizando el caso de uso del spam de correo que mencionamos anteriormente, con un enfoque tradicional haríamos lo siguiente:\n  Observaríamos que en los correos de spam aparecen palabras del tipo “para ti”, “gratis”, “increíble”, etc.\n  Codificaríamos un procedimiento que detectara estas palabras y etiquetaríamos como spam aquellos correos que contuvieran estos patrones.\n  Iteraríamos tantas veces por los dos pasos anteriores para codificar tantas reglas como patrones detectemos.\n  Un enfoque basado en técnicas de machine learning se centraría en aprender qué palabras o frases aparecen con mayor frecuencia en correos etiquetados como spam en comparación con correos “buenos”. Es lo que se denomina “entrenar” nuestro modelo, con el objetivo de que pueda clasificar los nuevos correos que nos lleguen.\nAdemás, supongamos que nuestro inteligente spammer compulsivo detecta que le bloqueamos aquellos correos donde aparece la palabra “gratis” y empieza a sustituirla por la palabra “gratuito”, y así sucesivamente cambiando las reglas. Un enfoque tradicional nos obligaría a estar constantemente cambiando nuestros patrones de detección y haciendo re-entregas. Un enfoque basado en ML detectaría automáticamente estos patrones inusualmente frecuentes en los correos marcados como spam y los marcaría en el futuro sin intervención humana.\nOtro campo donde realmente brilla machine learning es en el reconocimiento de escritura manual (o del habla). Podríamos escribir un programa que detectara determinados trazos o incluso el alfabeto completo, pero esto no escalaría a los miles de combinaciones escritas por millones de personas en el mundo. La mejor forma sería entrenar un modelo de ML proporcionándole muchos ejemplos de diferentes tipos de letras y patrones escritos a mano.\nComo vemos, machine learning es ideal para procesos donde tengamos mucho ajuste manual o un gran número de reglas, soluciones donde haya que adaptarse a nuevos datos, tratamiento de información no estructurada (sonidos, imágenes) y un largo etcétera de casos de uso.\nClasificación de los sistemas de machine learning Existen formas muy diversas de clasificar los sistemas de machine learning. Las más comunes serían las siguientes:\n  Si son entrenados con supervisión humana se pueden clasificar en: supervisados, no supervisados, semisupervisados y aprendizaje por reforzamiento.\n  Si pueden aprender incrementalmente al vuelo: aprendizaje online y aprendizaje por lotes.\n  Aprendizaje basado en instancia (donde los sistemas aprenden ejemplos “de memoria” y después generalizan a nuevos ejemplos usando medidas de similitud) vs aprendizaje basado en modelo (el sistema crea un modelo a partir de ejemplos de entrenamiento que usará posteriormente para realizar predicciones).\n  Esta tipología no es excluyente. Nuestro sistema de spam podría ser un ejemplo de aprendizaje supervisado online basado en modelo si lo entrenamos con una red neuronal.\nVeamos un poco más cerca nuestra primera categorización. Una mañana cualquiera nos acercamos a nuestro “banco amigo” a pedir un préstamo para montar nuestro soñado puesto de castañas. Después de rellenar varios formularios con datos de todo tipo, el director de la sucursal nos convoca para la semana siguiente, donde nos comunicará si nos concede dicho préstamo. ¿Cómo sabe el banco si devolveremos el préstamo? El banco tiene información de otros cientos de miles de operaciones similares a la nuestra y conoce si el cliente devolvió el préstamo o no (es decir, tiene datos etiquetados, aprendizaje supervisado). Con los datos que les hemos proporcionado y con sus modelos de clasificación, el banco puede predecir con un nivel de probabilidad en qué medida seremos capaces de devolver el préstamo. Queda a criterio del director de la sucursal si confiar ciegamente en lo que pronostican dichos modelos.\nEn el aprendizaje no supervisado no disponemos de datos etiquetados, por lo que el sistema debe aprender sin contar con un profesor. Los algoritmos no supervisados son muy útiles para detectar relaciones o agrupaciones entre los datos, algo que a una persona le resultaría muy difícil detectar. Por ejemplo, los modelos detrás de las empresas de venta online pueden detectar que las personas que compran un determinado producto X también suelen comprar el producto Z, por lo que nos los suelen sugerir (“Tal vez le interese…”, “Otros clientes también compraron…”, etc.) durante el proceso de compra. Este tipo de algoritmos no supervisados también se usan para la detección de anomalías (muy útil en la prevención del fraude bancario o en la detección de defectos de fabricación). El sistema está entrenado con ejemplos normales, por lo que es capaz de determinar si una nueva instancia es o no una anomalía.\nAlgunos sistemas de clasificación de imágenes serían un ejemplo de aprendizaje semisupervisado: son capaces de detectar personas y probablemente determinará que la persona X aparece en el siguiente grupo de imágenes. Tan solo hay que ayudarle indicándole quién es esa persona para que a la siguiente ocasión sepa etiquetarla correctamente.\nPor último, el aprendizaje por reforzamiento es un tipo muy diferente a los anteriores. El sistema obtiene recompensas o penalizaciones en función de sus acciones. Debe aprender a partir de ellas, eligiendo cuál sería la mejor estrategia (denominada política) para obtener la mayor recompensa a lo largo del tiempo. AlphaGo sería un ejemplo de aprendizaje por refuerzo. Aprendió su política ganadora estudiando millones de partidas. Durante su combate con el campeón del mundo aplicó las políticas que había aprendido.\nEn posteriores artículos hablaremos también de algunos de los lenguajes más idóneos y la combinación de herramientas que tenemos a nuestra disposición para trabajar de forma inmediata en machine learning: Python, Jupyter Notebook, Scikit-Learn, Tensor-Flow, Keras, etc.\nRevisaremos cuáles son las fases principales de un proyecto típico de machine learning con ejemplos prácticos.\n¡Bienvenidos al mundo de machine learning!\nPor cierto, apenas 3 años después de su derrota por AlphaGo, Lee Sedol se retiró de las competiciones oficiales. Si tenéis oportunidad no dejéis de ver el documental AlphaGo – The movie, que narra la apasionante crónica del combate entre ambas “mentes”.\n","description":"","tags":["aprendizaje automático","machine learning"],"title":"Breve Introducción a Machine Learning","uri":"/posts/breve-introduccion-machine-learning/"}]
